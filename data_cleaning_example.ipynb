{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0272b6cb",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 2\n",
    "#### Student Name: Hazel Titley\n",
    "#### Student Number: 32565895\n",
    "\n",
    "Date: 17/09/2021\n",
    "\n",
    "Environment: Python 3.7.9 and Anaconda 2020.11\n",
    "\n",
    "Libraries used:\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* re\n",
    "* datetime\n",
    "* ast\n",
    "* networkx\n",
    "* sklearn\n",
    "* nltk\n",
    "* sympy\n",
    "* collections\n",
    "\n",
    "This code aims to clean dirty data, missing data, and outlier data from 3 separate files. It is split into 5 main sections:\n",
    "\n",
    "* Part 0 - importing data and libraries\n",
    "* Part 1 - imputing missing data \n",
    "* Part 2 - filtering outlier data\n",
    "* Part 3 - cleaning dirty data\n",
    "* Part 4 - exporting data\n",
    "\n",
    "Parts 1 to 3 deal with the processing of the data. The processes are outlined in more detail within each section. <br>\n",
    "<br>\n",
    "Note: Please ensure that the data is stored in the same directory as this jupyter file, otherwise the code will not run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ac113",
   "metadata": {},
   "source": [
    "## Part 0 - Importing libraries and data\n",
    "before any data can be processed, it needs to read in to the working memory, and the relevant libraries imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a27ee1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/hazeltitley/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import sympy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27478182",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>carrier_vehicle</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>delivery_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD221584</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST06498</td>\n",
       "      <td>COUR4108</td>\n",
       "      <td>-37.825367</td>\n",
       "      <td>144.982814</td>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>06:31:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('crispy corn', 1), ('momos', 1), ('mocktails...</td>\n",
       "      <td>20</td>\n",
       "      <td>88.784</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD185757</td>\n",
       "      <td>REST1572</td>\n",
       "      <td>CUST08996</td>\n",
       "      <td>COUR2623</td>\n",
       "      <td>-37.812679</td>\n",
       "      <td>144.959576</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>15:53:24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('pizza', 1), ('veg starter', 2)]</td>\n",
       "      <td>45</td>\n",
       "      <td>33.121</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD058245</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST09230</td>\n",
       "      <td>COUR2476</td>\n",
       "      <td>-37.799510</td>\n",
       "      <td>144.935378</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>22:48:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('chicken tenders', 3), ('yakhni pulao', 3), ...</td>\n",
       "      <td>0</td>\n",
       "      <td>146.830</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD182651</td>\n",
       "      <td>REST1572</td>\n",
       "      <td>CUST03209</td>\n",
       "      <td>COUR0581</td>\n",
       "      <td>-37.811442</td>\n",
       "      <td>144.927331</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>08:06:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('cocktails', 1), ('sea food', 3)]</td>\n",
       "      <td>0</td>\n",
       "      <td>37.940</td>\n",
       "      <td>4292.0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD189538</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST08767</td>\n",
       "      <td>COUR3877</td>\n",
       "      <td>-37.815733</td>\n",
       "      <td>144.982268</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>11:40:13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('gulab jamun', 2), ('pizza', 2), ('chicken b...</td>\n",
       "      <td>20</td>\n",
       "      <td>71.712</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.7549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD221584      REST1137   CUST06498   COUR4108    -37.825367    144.982814   \n",
       "1  ORD185757      REST1572   CUST08996   COUR2623    -37.812679    144.959576   \n",
       "2  ORD058245      REST1946   CUST09230   COUR2476    -37.799510    144.935378   \n",
       "3  ORD182651      REST1572   CUST03209   COUR0581    -37.811442    144.927331   \n",
       "4  ORD189538      REST1137   CUST08767   COUR3877    -37.815733    144.982268   \n",
       "\n",
       "         date      time  is_peak_time  is_weekend carrier_vehicle  \\\n",
       "0  2020-11-26  06:31:38             0           0       Motorbike   \n",
       "1  2020-09-27  15:53:24             0           1             Car   \n",
       "2  2020-11-24  22:48:47             0           0            Bike   \n",
       "3  2020-05-29  08:06:35             0           0            Bike   \n",
       "4  2020-12-28  11:40:13             0           0             Car   \n",
       "\n",
       "                                       shopping_cart  coupon_discount  \\\n",
       "0  [('crispy corn', 1), ('momos', 1), ('mocktails...               20   \n",
       "1                 [('pizza', 1), ('veg starter', 2)]               45   \n",
       "2  [('chicken tenders', 3), ('yakhni pulao', 3), ...                0   \n",
       "3                [('cocktails', 1), ('sea food', 3)]                0   \n",
       "4  [('gulab jamun', 2), ('pizza', 2), ('chicken b...               20   \n",
       "\n",
       "   order_price  shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0       88.784                         2742.0                    5   \n",
       "1       33.121                         1045.0                    3   \n",
       "2      146.830                         3312.0                   17   \n",
       "3       37.940                         4292.0                   21   \n",
       "4       71.712                         1576.0                    4   \n",
       "\n",
       "   restaurant_rating  delivery_charges  \n",
       "0                NaN            3.4576  \n",
       "1                NaN            3.6992  \n",
       "2                NaN            4.6442  \n",
       "3                NaN            4.1049  \n",
       "4                NaN            2.7549  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in files\n",
    "outlier_data = pd.read_csv(\"32565895_outlier.csv\")\n",
    "missing_data = pd.read_csv(\"32565895_missing.csv\")\n",
    "dirty_data = pd.read_csv(\"32565895_dirty.csv\")\n",
    "rest_data = pd.read_csv(\"restaurant_data_student.csv\")\n",
    "nodes = pd.read_csv(\"nodes.csv\")\n",
    "edges = pd.read_csv(\"edges.csv\")\n",
    "#inspecting one of the dataframes to ensure reading has been successful\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae805c",
   "metadata": {},
   "source": [
    "as can be seen the dataframes have been read in successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8c90c",
   "metadata": {},
   "source": [
    "## Part 1 - Imputing missing data\n",
    "In this section the missing data imputed. That is, the restaurant ratings and shortest distance values are filled in. This is done using Djikstras algorithm and Sentiment Analysis. The sentiment analysis requires analysis of the given restaurant reviews, and Djikstras requires the creation of a graph using the edges and nodes provided in the edges.csv and nodes.csv respectively. More detail is provided in the relevant sub headings.\n",
    "\n",
    "### 1.1 - calculating the rating\n",
    "the restaurant ratings are calculated using sentiment analysis. to calculate each rating, the reviews first need to be read in from the the restaurant_data_student.csv and evaluated as a list. for each review in the list, sentiment analysis is performed. This works by associating each word in the review with a polarity score which represents the underlying sentiment (high scores mean the word is positive in meaning, low means negative) (Bird et al., 2009). a normalised, aggregated score (compound score) can then be determined for each review. this is done using the nltk SentimentIntensityAnalyzer and associated polarity_scores. this is caluclated for every review, so an average compound review score can be caluclated. this is converted to a rating using the equation given in the assessment outline, and the scores saved to a dictionary. this dictionary can then be used to fill in the missing restaurant ratings in the data set. <br?\n",
    "N.B: these rating are used later to clean the dirty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8f7cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only calculating the rating for restaurants in my data set\n",
    "rests = missing_data[\"restaurant_id\"].unique()\n",
    "#creating a dictionary which will contain the determined ratings\n",
    "rest_rating = {}\n",
    "#calculating the ratings for each restaurant\n",
    "for rest in rests:\n",
    "    review_scores = []\n",
    "    for i in range(len(rest_data)):\n",
    "        #retrieving restaurant reviews from the csv\n",
    "        if rest == rest_data.loc[i, \"restaurant_id\"]:\n",
    "            #breaking reviews into list by regexing\n",
    "            reviews = ast.literal_eval(rest_data.loc[i, \"reviews_list\"])\n",
    "            break  \n",
    "    #calculating the compound score for each review\n",
    "    for review in reviews:\n",
    "        score = SentimentIntensityAnalyzer().polarity_scores(review)['compound'] # (Bird et al., 2009)\n",
    "        review_scores.append(score)\n",
    "    #averaging the compound score\n",
    "    rs = sum(review_scores)/len(review_scores)\n",
    "    #calculating rating using the given formula\n",
    "    rating = 10*(rs + 0.9623)/(1.9533)\n",
    "    #saving rating and corresponding restaurant id to dictionary\n",
    "    rest_rating[rest]= round(rating, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a77af90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'REST1137': 9.6, 'REST1572': 9.28, 'REST1946': 4.96, 'REST2155': 9.54, 'REST2185': 8.18}\n"
     ]
    }
   ],
   "source": [
    "#printing the rating to inspect\n",
    "print(rest_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fef3e",
   "metadata": {},
   "source": [
    "now the ratings have been calculated, the missing values can be imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285f851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling in the missing ratings\n",
    "for i in range(len(missing_data)):\n",
    "    rest_id = missing_data.loc[i, \"restaurant_id\"]\n",
    "    missing_data.loc[i, \"restaurant_rating\"] = rest_rating[rest_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441b3522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data[\"restaurant_rating\"].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5c468",
   "metadata": {},
   "source": [
    "this output indicates there are no null values left in this column so the imputation has been successful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a418ba",
   "metadata": {},
   "source": [
    "### 1.2 - calculating the shortest distance\n",
    "The shortest distance between customer and restaurant is caluclated using Djikstras algorithm (Wikipedia 2021). to do this a graph first needs to be created using the edges supplied in edges.csv. each edge is given a weight corresponding to distance. the shortest distance is then found by retrieving the target and source node, and using nx.single_source_dijkstra (Hagberg et al., 2008) to calculate the path distance. the missing values can then be filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f14bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating graph\n",
    "G = nx.Graph()\n",
    "#adding edges to graph with distance as attribute\n",
    "for i in range(len(edges)):\n",
    "    n1 = round(edges.loc[i, \"u\"])\n",
    "    n2 = round(edges.loc[i, \"v\"])\n",
    "    d = round(edges.loc[i, \"distance(m)\"])\n",
    "    G.add_edge(n1, n2, dist=d) #https://networkx.org/documentation/stable/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92bfc5f",
   "metadata": {},
   "source": [
    "now the graph has been successfully made, the shortest distance can be calculated for each entry in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514bc169",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>carrier_vehicle</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>delivery_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD221584</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST06498</td>\n",
       "      <td>COUR4108</td>\n",
       "      <td>-37.825367</td>\n",
       "      <td>144.982814</td>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>06:31:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('crispy corn', 1), ('momos', 1), ('mocktails...</td>\n",
       "      <td>20</td>\n",
       "      <td>88.784</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.60</td>\n",
       "      <td>3.4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD185757</td>\n",
       "      <td>REST1572</td>\n",
       "      <td>CUST08996</td>\n",
       "      <td>COUR2623</td>\n",
       "      <td>-37.812679</td>\n",
       "      <td>144.959576</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>15:53:24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('pizza', 1), ('veg starter', 2)]</td>\n",
       "      <td>45</td>\n",
       "      <td>33.121</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.28</td>\n",
       "      <td>3.6992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD058245</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST09230</td>\n",
       "      <td>COUR2476</td>\n",
       "      <td>-37.799510</td>\n",
       "      <td>144.935378</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>22:48:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('chicken tenders', 3), ('yakhni pulao', 3), ...</td>\n",
       "      <td>0</td>\n",
       "      <td>146.830</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.6442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD182651</td>\n",
       "      <td>REST1572</td>\n",
       "      <td>CUST03209</td>\n",
       "      <td>COUR0581</td>\n",
       "      <td>-37.811442</td>\n",
       "      <td>144.927331</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>08:06:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('cocktails', 1), ('sea food', 3)]</td>\n",
       "      <td>0</td>\n",
       "      <td>37.940</td>\n",
       "      <td>4292.0</td>\n",
       "      <td>21</td>\n",
       "      <td>9.28</td>\n",
       "      <td>4.1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD189538</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST08767</td>\n",
       "      <td>COUR3877</td>\n",
       "      <td>-37.815733</td>\n",
       "      <td>144.982268</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>11:40:13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('gulab jamun', 2), ('pizza', 2), ('chicken b...</td>\n",
       "      <td>20</td>\n",
       "      <td>71.712</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.60</td>\n",
       "      <td>2.7549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD221584      REST1137   CUST06498   COUR4108    -37.825367    144.982814   \n",
       "1  ORD185757      REST1572   CUST08996   COUR2623    -37.812679    144.959576   \n",
       "2  ORD058245      REST1946   CUST09230   COUR2476    -37.799510    144.935378   \n",
       "3  ORD182651      REST1572   CUST03209   COUR0581    -37.811442    144.927331   \n",
       "4  ORD189538      REST1137   CUST08767   COUR3877    -37.815733    144.982268   \n",
       "\n",
       "         date      time  is_peak_time  is_weekend carrier_vehicle  \\\n",
       "0  2020-11-26  06:31:38             0           0       Motorbike   \n",
       "1  2020-09-27  15:53:24             0           1             Car   \n",
       "2  2020-11-24  22:48:47             0           0            Bike   \n",
       "3  2020-05-29  08:06:35             0           0            Bike   \n",
       "4  2020-12-28  11:40:13             0           0             Car   \n",
       "\n",
       "                                       shopping_cart  coupon_discount  \\\n",
       "0  [('crispy corn', 1), ('momos', 1), ('mocktails...               20   \n",
       "1                 [('pizza', 1), ('veg starter', 2)]               45   \n",
       "2  [('chicken tenders', 3), ('yakhni pulao', 3), ...                0   \n",
       "3                [('cocktails', 1), ('sea food', 3)]                0   \n",
       "4  [('gulab jamun', 2), ('pizza', 2), ('chicken b...               20   \n",
       "\n",
       "   order_price  shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0       88.784                         2742.0                    5   \n",
       "1       33.121                         1045.0                    3   \n",
       "2      146.830                         3312.0                   17   \n",
       "3       37.940                         4292.0                   21   \n",
       "4       71.712                         1576.0                    4   \n",
       "\n",
       "   restaurant_rating  delivery_charges  \n",
       "0               9.60            3.4576  \n",
       "1               9.28            3.6992  \n",
       "2               4.96            4.6442  \n",
       "3               9.28            4.1049  \n",
       "4               9.60            2.7549  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#isolating the missing data\n",
    "m_dist_rows = missing_data[missing_data[\"shortest_distance_to_customer\"].isnull()].index.tolist()\n",
    "\n",
    "for i in m_dist_rows:\n",
    "    c_lat = missing_data.loc[i, \"customer_lat\"]\n",
    "    c_lon = missing_data.loc[i, \"customer_lon\"]\n",
    "    r_id = missing_data.loc[i, \"restaurant_id\"]\n",
    "    #finding restaurant node\n",
    "    for j in range(len(rest_data)):\n",
    "        if r_id == rest_data.loc[j, \"restaurant_id\"]:\n",
    "            r_node = rest_data.loc[j, \"rest_nodes\"]\n",
    "            break\n",
    "    #finding customer node\n",
    "    for k in range(len(nodes)):\n",
    "        if round(c_lat, 7) == round(nodes.loc[k, \"lat\"], 7) and round(c_lon, 7) == round(nodes.loc[k, \"lon\"], 7):\n",
    "            c_node = nodes.loc[k, \"node\"]\n",
    "            break\n",
    "    #calculating shortest path length (by distance)\n",
    "    distance,path=nx.single_source_dijkstra(G, source=r_node, target=c_node, weight='dist') \n",
    "    missing_data.loc[i, \"shortest_distance_to_customer\"] = int(distance)\n",
    "\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c2a75d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data[\"shortest_distance_to_customer\"].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2accb32c",
   "metadata": {},
   "source": [
    "this output indicates there are no null values left in this column so the imputation has been successful! However due to a bug converting numpy 64 values to integers, all data entries are followed by a \".0\". this is impossible to get rid of whilst keeping the data numeric, so for now it is ignored. Later on this can be removed by converting the values to strings and using regex to remove the \".0\" where it appears."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12556197",
   "metadata": {},
   "source": [
    "### 1.3 - training regression model\n",
    "to impute the missing delivery charges, a regression model needs to be created (Pedregosa et al., 2011). to evaluate the how well the model works it needs to be tested on unseen data. By comparing the predicted values to the listed, the goodness of fit can be evaluated (using RMSE and R^2). R^2 provides an indicator of how well the model explains variation in the data. Ideally it should be 1, however this data is expected to contain some noise, so this will not be possible. RMSE provides an indicator of error and hence should be minimised for a good fit. So the model can be effectively evaluated, the data needs to be split into training and testing sets (with neither containing nulls). The model can be trained on the training data, and validated on the test. Once validated, a new model can then be trained on the whole dataset (in order to capture the most variation), and used to impute missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29247719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating relevant columns\n",
    "md = pd.DataFrame(missing_data,columns=[\"restaurant_rating\", \"is_peak_time\", \"is_weekend\", \"travel_time_minutes\", 'delivery_charges'])\n",
    "#removing nulls\n",
    "md = md.dropna(how='any',axis=0)\n",
    "#splitting data into independent and dependent variables\n",
    "x = pd.DataFrame(md,columns=[\"restaurant_rating\", \"is_peak_time\", \"is_weekend\", \"travel_time_minutes\"]) \n",
    "y = pd.DataFrame(md,columns=['delivery_charges'])\n",
    "#splitting into test and training sets:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 100)\n",
    "# creating a Linear regression object and training it on the data\n",
    "intial_model = LinearRegression().fit(x_train,y_train) # (Pedregosa et al., 2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c187a0",
   "metadata": {},
   "source": [
    "the model has now been trained and can be tested on the unseen data to determine whether it is a good fit for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fcd2fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score is:  0.9568494652052737\n",
      "root_mean_squared error is:  0.20917087803626155\n"
     ]
    }
   ],
   "source": [
    "#predicting outcomes on the test set and using them to evaluate the model\n",
    "y_prediction =  intial_model.predict(x_test)\n",
    "predictions = y_test.copy()\n",
    "predictions['prediction'] = y_prediction\n",
    "predictions.head()\n",
    "#printing accuracy metrics\n",
    "print(\"r2 score is: \", r2_score(y_test,y_prediction))\n",
    "print(\"root_mean_squared error is: \",np.sqrt(mean_squared_error(y_test,y_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a61705",
   "metadata": {},
   "source": [
    "as can be seen, the RMSE is low and the r squared is high. This indicates this model is a good fit. This is expected (given the charges dependence on the values), but nice to be confirmed. To capture as much variation as possible in the data, its important to use a large training set. for this reason, a new model should be trained on the full data set for increased accuracy. This will make it better for filling in the missing values and identifying outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69652b",
   "metadata": {},
   "source": [
    "#### 1.3.1 - retraining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e07c76e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a model\n",
    "final_model = LinearRegression()\n",
    "#training it on the data\n",
    "final_model.fit(x,y) # (Pedregosa et al., 2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02172acd",
   "metadata": {},
   "source": [
    "the model has now been retrained on the full dataset, and can be used to impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5792cce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>carrier_vehicle</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>delivery_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD221584</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST06498</td>\n",
       "      <td>COUR4108</td>\n",
       "      <td>-37.825367</td>\n",
       "      <td>144.982814</td>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>06:31:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('crispy corn', 1), ('momos', 1), ('mocktails...</td>\n",
       "      <td>20</td>\n",
       "      <td>88.784</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.60</td>\n",
       "      <td>3.4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD185757</td>\n",
       "      <td>REST1572</td>\n",
       "      <td>CUST08996</td>\n",
       "      <td>COUR2623</td>\n",
       "      <td>-37.812679</td>\n",
       "      <td>144.959576</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>15:53:24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('pizza', 1), ('veg starter', 2)]</td>\n",
       "      <td>45</td>\n",
       "      <td>33.121</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.28</td>\n",
       "      <td>3.6992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD058245</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST09230</td>\n",
       "      <td>COUR2476</td>\n",
       "      <td>-37.799510</td>\n",
       "      <td>144.935378</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>22:48:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('chicken tenders', 3), ('yakhni pulao', 3), ...</td>\n",
       "      <td>0</td>\n",
       "      <td>146.830</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.6442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD182651</td>\n",
       "      <td>REST1572</td>\n",
       "      <td>CUST03209</td>\n",
       "      <td>COUR0581</td>\n",
       "      <td>-37.811442</td>\n",
       "      <td>144.927331</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>08:06:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('cocktails', 1), ('sea food', 3)]</td>\n",
       "      <td>0</td>\n",
       "      <td>37.940</td>\n",
       "      <td>4292.0</td>\n",
       "      <td>21</td>\n",
       "      <td>9.28</td>\n",
       "      <td>4.1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD189538</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST08767</td>\n",
       "      <td>COUR3877</td>\n",
       "      <td>-37.815733</td>\n",
       "      <td>144.982268</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>11:40:13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('gulab jamun', 2), ('pizza', 2), ('chicken b...</td>\n",
       "      <td>20</td>\n",
       "      <td>71.712</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.60</td>\n",
       "      <td>2.7549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD221584      REST1137   CUST06498   COUR4108    -37.825367    144.982814   \n",
       "1  ORD185757      REST1572   CUST08996   COUR2623    -37.812679    144.959576   \n",
       "2  ORD058245      REST1946   CUST09230   COUR2476    -37.799510    144.935378   \n",
       "3  ORD182651      REST1572   CUST03209   COUR0581    -37.811442    144.927331   \n",
       "4  ORD189538      REST1137   CUST08767   COUR3877    -37.815733    144.982268   \n",
       "\n",
       "         date      time  is_peak_time  is_weekend carrier_vehicle  \\\n",
       "0  2020-11-26  06:31:38             0           0       Motorbike   \n",
       "1  2020-09-27  15:53:24             0           1             Car   \n",
       "2  2020-11-24  22:48:47             0           0            Bike   \n",
       "3  2020-05-29  08:06:35             0           0            Bike   \n",
       "4  2020-12-28  11:40:13             0           0             Car   \n",
       "\n",
       "                                       shopping_cart  coupon_discount  \\\n",
       "0  [('crispy corn', 1), ('momos', 1), ('mocktails...               20   \n",
       "1                 [('pizza', 1), ('veg starter', 2)]               45   \n",
       "2  [('chicken tenders', 3), ('yakhni pulao', 3), ...                0   \n",
       "3                [('cocktails', 1), ('sea food', 3)]                0   \n",
       "4  [('gulab jamun', 2), ('pizza', 2), ('chicken b...               20   \n",
       "\n",
       "   order_price  shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0       88.784                         2742.0                    5   \n",
       "1       33.121                         1045.0                    3   \n",
       "2      146.830                         3312.0                   17   \n",
       "3       37.940                         4292.0                   21   \n",
       "4       71.712                         1576.0                    4   \n",
       "\n",
       "   restaurant_rating  delivery_charges  \n",
       "0               9.60            3.4576  \n",
       "1               9.28            3.6992  \n",
       "2               4.96            4.6442  \n",
       "3               9.28            4.1049  \n",
       "4               9.60            2.7549  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#isolating rows with missing data\n",
    "missing_rows = missing_data[missing_data[\"delivery_charges\"].isnull()].index.tolist()\n",
    "missing_vals = missing_data.iloc[missing_rows,:]\n",
    "missing_vals_x = pd.DataFrame(missing_vals,columns=[\"restaurant_rating\", \"is_peak_time\", \"is_weekend\", \"travel_time_minutes\"])\n",
    "missing_vals_x = missing_vals_x.apply(pd.to_numeric)\n",
    "#predicting values\n",
    "y_pred =  final_model.predict(missing_vals_x)\n",
    "#filling in dataframe\n",
    "missing_data.loc[missing_rows,\"delivery_charges\"] = y_pred\n",
    "missing_data[\"delivery_charges\"] = missing_data[\"delivery_charges\"].round(4)\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e9e889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if the dataframe has any missing data left\n",
    "missing_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5f6fb",
   "metadata": {},
   "source": [
    "No missing data remains, so all the missing values have been successfully imputed and Part 1 is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd1f5e",
   "metadata": {},
   "source": [
    "## Part 2 - filtering outlier data\n",
    "Outlier filtering is performed on the delivery_charges column in the outlier_data.csv file. This data is multivariate and depends on:\n",
    "* Travel time between restaurant and customer.\n",
    "* Whether the delivery occurred during a peak period.\n",
    "* Whether the delivery occurred during a weekend.\n",
    "* The restaurant rating <br>\n",
    "\n",
    "As the data is multivariate, it would be bad practise to remove outliers based off the delivery_charges value alone.\n",
    "as filtering on delivery charges alone could bias the data. for example, orders made during peak times on a weekend are likely to incur larger delivery fees, and are hence more likely to be removed during outlier filtering. To minimise bias and identify outliers, it is better practise to fit a multiple linear regression model based on the influencing factors (NIST 2013). the residuals can then be used to indentiy outliers. this makes the data univariate, so points can be removed via the boxplot method. As the outlier data contains outliers, these could impact the training of the model. Hence, the model should be trained on an alternative dataset. as the missing data is MCAR, it provides a suitable training dataset. Note: this regression model (final_model) has already been created in Part 1 in order to fill in the missing values, so this is just used again for outlier identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c6ee317",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting data for inspection\n",
    "%matplotlib inline\n",
    "bp = outlier_data.boxplot(column=\"delivery_charges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eaa431",
   "metadata": {},
   "source": [
    "as can be seen from the boxplot, the outliers are dense and grouped, this suggests the data is multivariate and that using this boxplot alone to identify outliers is a bad idea. this confirms the information given in the assessment outline. that is, an alternative method should be used to identify outliers (like residuals)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd0f12",
   "metadata": {},
   "source": [
    "### 2.1 calculating residuals\n",
    "the delivery charges are rpedicted using the final model from part 1. the residuals are just the difference between these values and the listed charges. the processing is done on a copy of the original dataframe, to avoid altering the data. identified outliers can then be removed from the original via indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "850b13f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>carrier_vehicle</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>delivery_charges</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>predicted_delivery_charges</th>\n",
       "      <th>residual_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD080681</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST13978</td>\n",
       "      <td>COUR2927</td>\n",
       "      <td>-37.813016</td>\n",
       "      <td>144.951538</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>08:38:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('roti', 3), ('paneer malai tikka', 1), ('but...</td>\n",
       "      <td>10</td>\n",
       "      <td>120.744</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8732</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.661440</td>\n",
       "      <td>-0.211760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD046142</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST11790</td>\n",
       "      <td>COUR4300</td>\n",
       "      <td>-37.804585</td>\n",
       "      <td>144.967553</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>12:11:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('shahi paneer', 3), ('rajma', 2), ('biryani'...</td>\n",
       "      <td>45</td>\n",
       "      <td>74.640</td>\n",
       "      <td>3019</td>\n",
       "      <td>6</td>\n",
       "      <td>5.8251</td>\n",
       "      <td>8.18</td>\n",
       "      <td>5.879397</td>\n",
       "      <td>0.054297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD005100</td>\n",
       "      <td>REST2155</td>\n",
       "      <td>CUST06044</td>\n",
       "      <td>COUR1049</td>\n",
       "      <td>-37.806317</td>\n",
       "      <td>144.941575</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>17:16:29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('butter kulcha', 1), ('thali', 3)]</td>\n",
       "      <td>20</td>\n",
       "      <td>37.680</td>\n",
       "      <td>5828</td>\n",
       "      <td>12</td>\n",
       "      <td>3.9266</td>\n",
       "      <td>9.54</td>\n",
       "      <td>3.762545</td>\n",
       "      <td>-0.164055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD030320</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST07409</td>\n",
       "      <td>COUR1647</td>\n",
       "      <td>-37.823595</td>\n",
       "      <td>144.967131</td>\n",
       "      <td>2020-11-28</td>\n",
       "      <td>01:50:46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('momos', 3), ('chicken kebab', 2), ('crispy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>92.700</td>\n",
       "      <td>2344</td>\n",
       "      <td>12</td>\n",
       "      <td>4.7621</td>\n",
       "      <td>9.60</td>\n",
       "      <td>4.773202</td>\n",
       "      <td>0.011102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD312831</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST00686</td>\n",
       "      <td>COUR1688</td>\n",
       "      <td>-37.817256</td>\n",
       "      <td>144.962170</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>04:17:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('custard', 1), ('jeera rice', 3), ('protein ...</td>\n",
       "      <td>0</td>\n",
       "      <td>62.260</td>\n",
       "      <td>1085</td>\n",
       "      <td>5</td>\n",
       "      <td>3.4256</td>\n",
       "      <td>8.18</td>\n",
       "      <td>3.279025</td>\n",
       "      <td>-0.146575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD080681      REST1946   CUST13978   COUR2927    -37.813016    144.951538   \n",
       "1  ORD046142      REST2185   CUST11790   COUR4300    -37.804585    144.967553   \n",
       "2  ORD005100      REST2155   CUST06044   COUR1049    -37.806317    144.941575   \n",
       "3  ORD030320      REST1137   CUST07409   COUR1647    -37.823595    144.967131   \n",
       "4  ORD312831      REST2185   CUST00686   COUR1688    -37.817256    144.962170   \n",
       "\n",
       "         date      time  is_peak_time  is_weekend carrier_vehicle  \\\n",
       "0  2020-08-04  08:38:14             0           0             Car   \n",
       "1  2020-02-16  12:11:52             1           1       Motorbike   \n",
       "2  2020-07-16  17:16:29             0           0       Motorbike   \n",
       "3  2020-11-28  01:50:46             0           1            Bike   \n",
       "4  2020-06-08  04:17:08             0           0            Bike   \n",
       "\n",
       "                                       shopping_cart  coupon_discount  \\\n",
       "0  [('roti', 3), ('paneer malai tikka', 1), ('but...               10   \n",
       "1  [('shahi paneer', 3), ('rajma', 2), ('biryani'...               45   \n",
       "2               [('butter kulcha', 1), ('thali', 3)]               20   \n",
       "3  [('momos', 3), ('chicken kebab', 2), ('crispy ...                0   \n",
       "4  [('custard', 1), ('jeera rice', 3), ('protein ...                0   \n",
       "\n",
       "   order_price  shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0      120.744                           1792                    4   \n",
       "1       74.640                           3019                    6   \n",
       "2       37.680                           5828                   12   \n",
       "3       92.700                           2344                   12   \n",
       "4       62.260                           1085                    5   \n",
       "\n",
       "   delivery_charges  restaurant_rating  predicted_delivery_charges  \\\n",
       "0            3.8732               4.96                    3.661440   \n",
       "1            5.8251               8.18                    5.879397   \n",
       "2            3.9266               9.54                    3.762545   \n",
       "3            4.7621               9.60                    4.773202   \n",
       "4            3.4256               8.18                    3.279025   \n",
       "\n",
       "   residual_value  \n",
       "0       -0.211760  \n",
       "1        0.054297  \n",
       "2       -0.164055  \n",
       "3        0.011102  \n",
       "4       -0.146575  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resdiuals are calculated on a copy of the outlier_data (so as to not uneccessarily alter it)\n",
    "od = outlier_data.copy()\n",
    "#creating restaurant rating column\n",
    "od.loc[i, \"restaurant_rating\"] = 0\n",
    "#setting rating values\n",
    "for i in range(len(od)):\n",
    "    rest_id = od.loc[i, \"restaurant_id\"]\n",
    "    od.loc[i, \"restaurant_rating\"] = rest_rating[rest_id]\n",
    "#isolating x variables\n",
    "od_x = pd.DataFrame(od,columns=[\"restaurant_rating\", \"is_peak_time\", \"is_weekend\", \"travel_time_minutes\"])\n",
    "od_x = od_x.apply(pd.to_numeric)\n",
    "#predicting delivery_charge values\n",
    "y_pred =  final_model.predict(od_x)\n",
    "#saving predictions to dataframe\n",
    "od['predicted_delivery_charges'] = y_pred\n",
    "#saving residuals\n",
    "od['residual_value'] = od['predicted_delivery_charges'] - od['delivery_charges']\n",
    "od.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98e589",
   "metadata": {},
   "source": [
    "as can be seen, predicted an residual values have been added to this copy of the dataframe, indicating the calculations have been successful. now the outliers can be identified from their residual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6dd869",
   "metadata": {},
   "source": [
    "### 2.2 identifying outliers by the boxplot method\n",
    "A boxplot provides a low dimensional subspace for outlier detection. using this method, an outlier is defined as any point that lies outside the whiskers of the box plot (NIST 2013). That is, 1.5 times the interquartile range above the upper quartile or 1.5 times the interquartile range below the lower quartile. these values are calculated and used to flag outlier data. the indexes of these values are then identified and used to remove data from the original dataframe. The boxplots can then be plotted again, to confirm filtering success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bcefdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>delivery_charges</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>predicted_delivery_charges</th>\n",
       "      <th>residual_value</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD080681</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST13978</td>\n",
       "      <td>COUR2927</td>\n",
       "      <td>-37.813016</td>\n",
       "      <td>144.951538</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>08:38:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[('roti', 3), ('paneer malai tikka', 1), ('but...</td>\n",
       "      <td>10</td>\n",
       "      <td>120.744</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8732</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.661440</td>\n",
       "      <td>-0.211760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD046142</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST11790</td>\n",
       "      <td>COUR4300</td>\n",
       "      <td>-37.804585</td>\n",
       "      <td>144.967553</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>12:11:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[('shahi paneer', 3), ('rajma', 2), ('biryani'...</td>\n",
       "      <td>45</td>\n",
       "      <td>74.640</td>\n",
       "      <td>3019</td>\n",
       "      <td>6</td>\n",
       "      <td>5.8251</td>\n",
       "      <td>8.18</td>\n",
       "      <td>5.879397</td>\n",
       "      <td>0.054297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD005100</td>\n",
       "      <td>REST2155</td>\n",
       "      <td>CUST06044</td>\n",
       "      <td>COUR1049</td>\n",
       "      <td>-37.806317</td>\n",
       "      <td>144.941575</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>17:16:29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[('butter kulcha', 1), ('thali', 3)]</td>\n",
       "      <td>20</td>\n",
       "      <td>37.680</td>\n",
       "      <td>5828</td>\n",
       "      <td>12</td>\n",
       "      <td>3.9266</td>\n",
       "      <td>9.54</td>\n",
       "      <td>3.762545</td>\n",
       "      <td>-0.164055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD030320</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST07409</td>\n",
       "      <td>COUR1647</td>\n",
       "      <td>-37.823595</td>\n",
       "      <td>144.967131</td>\n",
       "      <td>2020-11-28</td>\n",
       "      <td>01:50:46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[('momos', 3), ('chicken kebab', 2), ('crispy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>92.700</td>\n",
       "      <td>2344</td>\n",
       "      <td>12</td>\n",
       "      <td>4.7621</td>\n",
       "      <td>9.60</td>\n",
       "      <td>4.773202</td>\n",
       "      <td>0.011102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD312831</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST00686</td>\n",
       "      <td>COUR1688</td>\n",
       "      <td>-37.817256</td>\n",
       "      <td>144.962170</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>04:17:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[('custard', 1), ('jeera rice', 3), ('protein ...</td>\n",
       "      <td>0</td>\n",
       "      <td>62.260</td>\n",
       "      <td>1085</td>\n",
       "      <td>5</td>\n",
       "      <td>3.4256</td>\n",
       "      <td>8.18</td>\n",
       "      <td>3.279025</td>\n",
       "      <td>-0.146575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD080681      REST1946   CUST13978   COUR2927    -37.813016    144.951538   \n",
       "1  ORD046142      REST2185   CUST11790   COUR4300    -37.804585    144.967553   \n",
       "2  ORD005100      REST2155   CUST06044   COUR1049    -37.806317    144.941575   \n",
       "3  ORD030320      REST1137   CUST07409   COUR1647    -37.823595    144.967131   \n",
       "4  ORD312831      REST2185   CUST00686   COUR1688    -37.817256    144.962170   \n",
       "\n",
       "         date      time  is_peak_time  is_weekend  ...  \\\n",
       "0  2020-08-04  08:38:14             0           0  ...   \n",
       "1  2020-02-16  12:11:52             1           1  ...   \n",
       "2  2020-07-16  17:16:29             0           0  ...   \n",
       "3  2020-11-28  01:50:46             0           1  ...   \n",
       "4  2020-06-08  04:17:08             0           0  ...   \n",
       "\n",
       "                                       shopping_cart coupon_discount  \\\n",
       "0  [('roti', 3), ('paneer malai tikka', 1), ('but...              10   \n",
       "1  [('shahi paneer', 3), ('rajma', 2), ('biryani'...              45   \n",
       "2               [('butter kulcha', 1), ('thali', 3)]              20   \n",
       "3  [('momos', 3), ('chicken kebab', 2), ('crispy ...               0   \n",
       "4  [('custard', 1), ('jeera rice', 3), ('protein ...               0   \n",
       "\n",
       "   order_price  shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0      120.744                           1792                    4   \n",
       "1       74.640                           3019                    6   \n",
       "2       37.680                           5828                   12   \n",
       "3       92.700                           2344                   12   \n",
       "4       62.260                           1085                    5   \n",
       "\n",
       "   delivery_charges  restaurant_rating  predicted_delivery_charges  \\\n",
       "0            3.8732               4.96                    3.661440   \n",
       "1            5.8251               8.18                    5.879397   \n",
       "2            3.9266               9.54                    3.762545   \n",
       "3            4.7621               9.60                    4.773202   \n",
       "4            3.4256               8.18                    3.279025   \n",
       "\n",
       "   residual_value  flag  \n",
       "0       -0.211760     0  \n",
       "1        0.054297     0  \n",
       "2       -0.164055     0  \n",
       "3        0.011102     0  \n",
       "4       -0.146575     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating quartiles and IQR\n",
    "third_q = od.quantile(0.75, axis=0)[\"residual_value\"]\n",
    "first_q = od.quantile(0.25, axis=0)[\"residual_value\"]\n",
    "iqr = third_q-first_q\n",
    "\n",
    "#creating flag column\n",
    "od[\"flag\"] = 0\n",
    "#falgging data if it lies outside of whisker values\n",
    "for i in range(len(od)):\n",
    "    upper_lim = third_q + 1.5*iqr\n",
    "    lower_lim = first_q - 1.5*iqr\n",
    "    if od.loc[i, \"residual_value\"] > upper_lim or od.loc[i, \"residual_value\"] < lower_lim:\n",
    "        od.loc[i, \"flag\"] = 1\n",
    "\n",
    "od.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25477f36",
   "metadata": {},
   "source": [
    "as can be seen, a flag value has been given to each row, with a value of 1 indicating an outlier. these values can be removed from the original dataframe by indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0f3478e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>carrier_vehicle</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>delivery_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD080681</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST13978</td>\n",
       "      <td>COUR2927</td>\n",
       "      <td>-37.813016</td>\n",
       "      <td>144.951538</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>08:38:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('roti', 3), ('paneer malai tikka', 1), ('but...</td>\n",
       "      <td>10</td>\n",
       "      <td>120.744</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD046142</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST11790</td>\n",
       "      <td>COUR4300</td>\n",
       "      <td>-37.804585</td>\n",
       "      <td>144.967553</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>12:11:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('shahi paneer', 3), ('rajma', 2), ('biryani'...</td>\n",
       "      <td>45</td>\n",
       "      <td>74.640</td>\n",
       "      <td>3019</td>\n",
       "      <td>6</td>\n",
       "      <td>5.8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD005100</td>\n",
       "      <td>REST2155</td>\n",
       "      <td>CUST06044</td>\n",
       "      <td>COUR1049</td>\n",
       "      <td>-37.806317</td>\n",
       "      <td>144.941575</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>17:16:29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('butter kulcha', 1), ('thali', 3)]</td>\n",
       "      <td>20</td>\n",
       "      <td>37.680</td>\n",
       "      <td>5828</td>\n",
       "      <td>12</td>\n",
       "      <td>3.9266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD030320</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST07409</td>\n",
       "      <td>COUR1647</td>\n",
       "      <td>-37.823595</td>\n",
       "      <td>144.967131</td>\n",
       "      <td>2020-11-28</td>\n",
       "      <td>01:50:46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('momos', 3), ('chicken kebab', 2), ('crispy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>92.700</td>\n",
       "      <td>2344</td>\n",
       "      <td>12</td>\n",
       "      <td>4.7621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD312831</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST00686</td>\n",
       "      <td>COUR1688</td>\n",
       "      <td>-37.817256</td>\n",
       "      <td>144.962170</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>04:17:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('custard', 1), ('jeera rice', 3), ('protein ...</td>\n",
       "      <td>0</td>\n",
       "      <td>62.260</td>\n",
       "      <td>1085</td>\n",
       "      <td>5</td>\n",
       "      <td>3.4256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD080681      REST1946   CUST13978   COUR2927    -37.813016    144.951538   \n",
       "1  ORD046142      REST2185   CUST11790   COUR4300    -37.804585    144.967553   \n",
       "2  ORD005100      REST2155   CUST06044   COUR1049    -37.806317    144.941575   \n",
       "3  ORD030320      REST1137   CUST07409   COUR1647    -37.823595    144.967131   \n",
       "4  ORD312831      REST2185   CUST00686   COUR1688    -37.817256    144.962170   \n",
       "\n",
       "         date      time  is_peak_time  is_weekend carrier_vehicle  \\\n",
       "0  2020-08-04  08:38:14             0           0             Car   \n",
       "1  2020-02-16  12:11:52             1           1       Motorbike   \n",
       "2  2020-07-16  17:16:29             0           0       Motorbike   \n",
       "3  2020-11-28  01:50:46             0           1            Bike   \n",
       "4  2020-06-08  04:17:08             0           0            Bike   \n",
       "\n",
       "                                       shopping_cart  coupon_discount  \\\n",
       "0  [('roti', 3), ('paneer malai tikka', 1), ('but...               10   \n",
       "1  [('shahi paneer', 3), ('rajma', 2), ('biryani'...               45   \n",
       "2               [('butter kulcha', 1), ('thali', 3)]               20   \n",
       "3  [('momos', 3), ('chicken kebab', 2), ('crispy ...                0   \n",
       "4  [('custard', 1), ('jeera rice', 3), ('protein ...                0   \n",
       "\n",
       "   order_price  shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0      120.744                           1792                    4   \n",
       "1       74.640                           3019                    6   \n",
       "2       37.680                           5828                   12   \n",
       "3       92.700                           2344                   12   \n",
       "4       62.260                           1085                    5   \n",
       "\n",
       "   delivery_charges  \n",
       "0            3.8732  \n",
       "1            5.8251  \n",
       "2            3.9266  \n",
       "3            4.7621  \n",
       "4            3.4256  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding indexes with flagged data\n",
    "indexes = od.index[od[\"flag\"]==1].tolist()\n",
    "#removing outliers from dataset according to index value\n",
    "outlier_data = outlier_data.drop(indexes)\n",
    "outlier_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1364c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting data\n",
    "%matplotlib inline\n",
    "bp = outlier_data.boxplot(column=\"delivery_charges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8259cef",
   "metadata": {},
   "source": [
    "As can be seen, a significant portion of the outliers have been removed, indicating the filtering was successful adn part 2 is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d3d0c",
   "metadata": {},
   "source": [
    "## Part 3 -  cleaning the dirty data\n",
    "as each line of code only contains one error, an index of changes made is kept to ensure each line is only fixed once. I begin by fixing easy errors. By this I mean i check for syntactic errors (like incorrectly saved dates), or errors which only affect a single column. After that, more complex issues are fixed. This is done by looking for contradictions within the data (like ensuring is_weekend is correct for the given date). Fixing the order price and delivery time are the most complex process for this data processing, and these are done last. The order price issue is complex as it requires the use of linear algebra to determine the price of the menu items, and is impacted by the discount given. where the dicount coupon can be changed to produce the given order price, this is done, otherwise the order price is changed. delivery_time is also complicated as it depends on the vehicle and the shortest path calculated. Djikstras is used to validate the shortest path. Where the carrier vehicle can be altered to produce the given time, this is done, otherwise the time is altered. The steps are explained in further detail below, as they are executed. The steps are outlined in more detail at each subheading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de56d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising index\n",
    "changed_i = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a05ef",
   "metadata": {},
   "source": [
    "### 3.1 - fixing latitude and longitude\n",
    "as latitude values are only valid where they are between -90 and 90, errors are easy to identify. the same goes for longitude (except the range is 80 to 180). errors are likely to be due to misplacement of the values. that is, accidentally saving the latitude under the longitude column, and longitude under latitude. Hence, these errors can be fixed by swapping the values into their correct columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d55a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data to numeric\n",
    "dirty_data[\"customer_lat\"] = pd.to_numeric(dirty_data[\"customer_lat\"])\n",
    "dirty_data[\"customer_lon\"] = pd.to_numeric(dirty_data[\"customer_lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fa698a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA CONTAINS ERROR\n"
     ]
    }
   ],
   "source": [
    "#checking if their is invalid data\n",
    "for i in range(len(dirty_data)):\n",
    "    if float(dirty_data.loc[i, \"customer_lon\"])<80 or float(dirty_data.loc[i, \"customer_lon\"])>180 or abs(float(dirty_data.loc[i, \"customer_lat\"]))>90:\n",
    "        print(\"DATA CONTAINS ERROR\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4530a",
   "metadata": {},
   "source": [
    "as per the output, the dataset contains at least one invalid longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce0034ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAT AND LON SWAPPED AT INDEX: 6\n",
      "LAT AND LON SWAPPED AT INDEX: 197\n",
      "LAT AND LON SWAPPED AT INDEX: 274\n",
      "LAT AND LON SWAPPED AT INDEX: 426\n",
      "LAT AND LON SWAPPED AT INDEX: 490\n",
      "LAT AND LON SWAPPED AT INDEX: 492\n"
     ]
    }
   ],
   "source": [
    "#looping through the data\n",
    "for i in range(len(dirty_data)):\n",
    "    # if the latitude is wrong, ans so is the longitude, the values are swapped\n",
    "    if abs(float(dirty_data.loc[i, \"customer_lat\"]))>90:\n",
    "        if float(dirty_data.loc[i, \"customer_lon\"])<80 or float(dirty_data.loc[i, \"customer_lon\"])>180:\n",
    "            #swapping values around\n",
    "            print(\"LAT AND LON SWAPPED AT INDEX: {}\".format(i))\n",
    "            changed_i.append(i)\n",
    "            lat = float(dirty_data.loc[i, \"customer_lat\"])\n",
    "            lon = float(dirty_data.loc[i, \"customer_lon\"])\n",
    "            dirty_data.loc[i, \"customer_lat\"] = lon\n",
    "            dirty_data.loc[i, \"customer_lon\"] = lat\n",
    "        else:\n",
    "            print(\"WEIRD DATA - latitude is incorrect but longitude appears correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1cac1",
   "metadata": {},
   "source": [
    "checking the data no longer contains any issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0a5edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SUCCESSFULLY FIXED\n"
     ]
    }
   ],
   "source": [
    "#looping through data\n",
    "for i in range(len(dirty_data)):\n",
    "    error = False\n",
    "    #printing error if invalid longitude or latitude found\n",
    "    if float(dirty_data.loc[i, \"customer_lon\"])<80 or float(dirty_data.loc[i, \"customer_lon\"])>180:\n",
    "        print(\"DATA STILL CONTAINS ERROR\")\n",
    "        error = True\n",
    "        break\n",
    "if not error:\n",
    "    print(\"DATA SUCCESSFULLY FIXED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac723fa",
   "metadata": {},
   "source": [
    "this confirms that the columns have been successfully cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8885f64",
   "metadata": {},
   "source": [
    "### 3.2 - fixing dates and checking time\n",
    "the date and time formats are checked to ensure they are valid\n",
    "#### 3.2.1 - fixing dates\n",
    "the date column is likely to contain some syntactical errors, so needs to be checked. incorrectly formated dates are saved with the index as tuples to a list. Regexing is then used to process the dates and automatically convert them to a valid format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db6637d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR - unable to convert data to date at index: 60, FORMAT: 2020-20-11\n",
      "ERROR - unable to convert data to date at index: 98, FORMAT: 2020-27-09\n",
      "ERROR - unable to convert data to date at index: 153, FORMAT: 2020-Oct-07\n",
      "ERROR - unable to convert data to date at index: 155, FORMAT: Fri Apr 10 00:00:00 2020\n",
      "ERROR - unable to convert data to date at index: 166, FORMAT: 2020-24-01\n",
      "ERROR - unable to convert data to date at index: 205, FORMAT: 2020-26-12\n",
      "ERROR - unable to convert data to date at index: 236, FORMAT: 2020-26-02\n",
      "ERROR - unable to convert data to date at index: 265, FORMAT: Fri Dec  4 00:00:00 2020\n",
      "ERROR - unable to convert data to date at index: 381, FORMAT: 2020-16-12\n",
      "ERROR - unable to convert data to date at index: 442, FORMAT: 2020-24-10\n"
     ]
    }
   ],
   "source": [
    "#isolating incorrectly formatted dates\n",
    "date_errors = []\n",
    "for i, item in enumerate(dirty_data['date']):\n",
    "    try:\n",
    "        fixed_data = datetime.strptime(item, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        date_errors.append(tuple((i, item)))\n",
    "        print('ERROR - unable to convert data to date at index: {}, FORMAT: {}'.format(i, item))\n",
    "        changed_i.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393097f",
   "metadata": {},
   "source": [
    "As can be seen, some of the date values are invalid or in the incorrect format. There arent many errors, so these could be fixed manually. However automating the process allows the process to be implemented on larger datasets (so this is what is done). where the months are too large, but the date (day) could be considered months, these are assumed to be in the wrong order and swapped. where the month is listed by its name, it is just converted to numeric. time stamps and day names are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "289a13e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(60, '2020-11-20'), (98, '2020-09-27'), (153, '2020-10-07'), (155, '2020-04-10'), (166, '2020-01-24'), (205, '2020-12-26'), (236, '2020-02-26'), (265, '2020-12-04'), (381, '2020-12-16'), (442, '2020-10-24')]\n"
     ]
    }
   ],
   "source": [
    "#converting dates to consistent format\n",
    "fixed_dates = []\n",
    "for item in date_errors:\n",
    "    #where the month/day are in the wrong order, but otherwise the format is correct, the string \n",
    "    #is of length 10, and the values can just be swapped using slicing\n",
    "    if len(item[1])==10:\n",
    "        #if the month is too large, and the day value could be a valid month\n",
    "        if int(item[1][5:7])>12 and int(item[1][8:10])<13:\n",
    "            #restructuring date\n",
    "            d = str(item[1][0:4])+\"-\"+str(item[1][8:10])+\"-\"+str(item[1][5:7])\n",
    "            #appending to fixed list\n",
    "            fixed_dates.append(tuple((item[0], d)))\n",
    "    # if the only thing wrong with the date is that the mongth is listed by name (not number)\n",
    "    #this is converted to its month number using strptime\n",
    "    elif re.search(r'\\-([a-zA-Z]{3})\\-', item[1]):\n",
    "        m = re.search(r'\\-([a-zA-Z]{3})\\-', item[1]).group(1) #finding match\n",
    "        num_m = datetime.strptime(m, \"%b\").month #extracting month\n",
    "        #the month number is given as two digits, but strptime returns some single digits, so a\n",
    "        # 0 needs to be appended to the front of these values\n",
    "        if len(str(num_m)) == 1: \n",
    "            num_m = \"0\"+str(num_m)\n",
    "        #reformatting date\n",
    "        fixed = str(item[1][0:4])+\"-\"+ str(num_m)+\"-\"+str(item[1][-2:])\n",
    "        fixed_dates.append(tuple((item[0], fixed)))\n",
    "    #if all the date values are mixed in, in a strange format the month, date and year can be found using regex\n",
    "    else:\n",
    "        #isolating month\n",
    "        mon = re.search(r' ([a-zA-Z]{3}) ', item[1])\n",
    "        #isolating day\n",
    "        days = re.search(r' (\\d{1,2}) ', item[1])\n",
    "        #isolating year\n",
    "        y = re.search(r'\\d{4}', item[1])\n",
    "        #checking matches have been found\n",
    "        if mon and days and y:\n",
    "            m = mon.group(1)\n",
    "            day = days.group(1)\n",
    "            num_y = y.group()\n",
    "            #formatting date\n",
    "            num_m = datetime.strptime(m, \"%b\").month\n",
    "            if len(str(num_m)) == 1:\n",
    "                num_m = \"0\"+str(num_m)\n",
    "            if len(str(day)) == 1:\n",
    "                day = \"0\"+str(day)\n",
    "            fixed = str(num_y)+\"-\"+str(num_m)+\"-\"+str(day)\n",
    "            fixed_dates.append(tuple((item[0], fixed)))\n",
    "            \n",
    "print(fixed_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e907c",
   "metadata": {},
   "source": [
    "the fixed dates and their index are returned as a dictionary so they can be used to fix the dataframe. as can be seen in the output, the fixing process has been successful, as all of these are valid dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d65eb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing incorrect dates with fixed ones\n",
    "for item in fixed_dates:\n",
    "    dirty_data.loc[item[0], \"date\"] = item[1]\n",
    "#converting column to date formate to ensure all erros have been fixed\n",
    "dirty_data['date']= pd.to_datetime(dirty_data['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f09efa",
   "metadata": {},
   "source": [
    "as the conversion didn't raise an error, this data has been fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc29619",
   "metadata": {},
   "source": [
    "#### 3.2.2 - checking time stamps are valid\n",
    "this is done by converting the time column to a timestamp using pd.to_datetime. as this alters the format (by adding an arbitrary date) it is done to a copy of the dataframe. if there is a invalid timestamp, and error would be raised, indicating the need for a fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c64f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dirty_data.copy()\n",
    "dd['time']= pd.to_datetime(dd['time'], format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0921e8",
   "metadata": {},
   "source": [
    "as the conversion didn't raise an error, this data is valid and does not require fixing.\n",
    "<br>\n",
    "### 3.3 - fixing peak values\n",
    "the data is checked to ensure the is_peak and time values match up. As the time data has already been checked for errors, if there is a contradiction between the time and is_peak information, the time is assumed correct and the peak value changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0411fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEAK VALUE CHANGED AT INDEX: 58 FROM: 1 TO: 0\n",
      "PEAK VALUE CHANGED AT INDEX: 297 FROM: 0 TO: 1\n",
      "PEAK VALUE CHANGED AT INDEX: 437 FROM: 1 TO: 0\n",
      "PEAK VALUE CHANGED AT INDEX: 449 FROM: 1 TO: 0\n",
      "PEAK VALUE CHANGED AT INDEX: 453 FROM: 1 TO: 0\n",
      "PEAK VALUE CHANGED AT INDEX: 480 FROM: 0 TO: 1\n"
     ]
    }
   ],
   "source": [
    "#looping through the data\n",
    "for i in range(len(dirty_data)):\n",
    "    time = pd.to_datetime(dirty_data.loc[i, \"time\"], format='%H:%M:%S')\n",
    "    #if the data is during a peak time\n",
    "    if time<pd.to_datetime(\"14:00:00\", format='%H:%M:%S') and time>=pd.to_datetime(\"12:00:00\", format='%H:%M:%S'):\n",
    "        if dirty_data.loc[i, \"is_peak_time\"] == 0:\n",
    "            print(\"PEAK VALUE CHANGED AT INDEX: {} FROM: 0 TO: 1\". format(i))\n",
    "            changed_i.append(i)\n",
    "            #set peak value to 1\n",
    "            dirty_data.loc[i, \"is_peak_time\"] = 1\n",
    "    #if the data is during a peak time\n",
    "    elif time<pd.to_datetime(\"20:00:00\", format='%H:%M:%S') and time>=pd.to_datetime(\"18:00:00\", format='%H:%M:%S'):\n",
    "        if dirty_data.loc[i, \"is_peak_time\"] == 0:\n",
    "            print(\"PEAK VALUE CHANGED AT INDEX: {} FROM: 0 TO: 1\". format(i))\n",
    "            changed_i.append(i)\n",
    "            #set peak value to 1\n",
    "            dirty_data.loc[i, \"is_peak_time\"] = 1\n",
    "    #if not in a peak period         \n",
    "    else:\n",
    "        if dirty_data.loc[i, \"is_peak_time\"] == 1:\n",
    "            print(\"PEAK VALUE CHANGED AT INDEX: {} FROM: 1 TO: 0\". format(i))\n",
    "            changed_i.append(i)\n",
    "            #set peak value to 0\n",
    "            dirty_data.loc[i, \"is_peak_time\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a903c69",
   "metadata": {},
   "source": [
    "as can be seen, a few of the values needed fixing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8faa1c",
   "metadata": {},
   "source": [
    "### 3.4 - fixing weekend values\n",
    "the data is checked to ensure the is_weekend and date values match up. As the date data has already been checked for errors, if there is a contradiction between the date and is_weekend values, the date is assumed correct and the weekend value changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86f2324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEEKEND VALUE CHANGED AT INDEX: 0 FROM: 0 TO: 1\n",
      "WEEKEND VALUE CHANGED AT INDEX: 184 FROM: 1 TO: 0\n",
      "WEEKEND VALUE CHANGED AT INDEX: 266 FROM: 0 TO: 1\n",
      "WEEKEND VALUE CHANGED AT INDEX: 309 FROM: 1 TO: 0\n",
      "WEEKEND VALUE CHANGED AT INDEX: 422 FROM: 1 TO: 0\n"
     ]
    }
   ],
   "source": [
    "#this is done similarly to the peak processing\n",
    "#the data is looped through\n",
    "for i in range(len(dirty_data)):\n",
    "    #if the date corresponds to a weekend, the weekend value should be 1\n",
    "    if dirty_data.loc[i, \"date\"].weekday()>4:\n",
    "        if dirty_data.loc[i, \"is_weekend\"] == 0:\n",
    "            print(\"WEEKEND VALUE CHANGED AT INDEX: {} FROM: 0 TO: 1\". format(i))\n",
    "            changed_i.append(i)\n",
    "            #changing weekend value to 1 if it is incorrect\n",
    "            dirty_data.loc[i, \"is_weekend\"] = 1\n",
    "    #if the date corresponds to a weekday, the weekend value should be 0\n",
    "    else:\n",
    "        if dirty_data.loc[i, \"is_weekend\"] == 1:\n",
    "            print(\"WEEKEND VALUE CHANGED AT INDEX: {} FROM: 1 TO: 0\". format(i))\n",
    "            changed_i.append(i)\n",
    "            #changing weekend value to 0 if it is incorrect\n",
    "            dirty_data.loc[i, \"is_weekend\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae7d6e",
   "metadata": {},
   "source": [
    "as can be seen, a few of the values needed fixing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e3fcd",
   "metadata": {},
   "source": [
    "### 3.5 - checking validity of coupon, rating, travel time, and delivery charges\n",
    "this section of code just checks the entry values are legitimate. that is, where a coupon is listed, it is a theorectical coupon value. it also check all the ratings are numbers below 10, the travel times are all integers, and the delivery charges are all floats. However, this does not mean that that these columns are error free. it just mean the values are theoretically legitimate if the other data is not taken into account. futher checking is required to determine data validity, and this is done later on. these checks are designed to identify any obvious errors in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "813f2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupons = [0, 10, 20, 40, 45]\n",
    "for i in range(len(dirty_data)):\n",
    "    if int(dirty_data.loc[i,\"coupon_discount\"]) not in coupons:\n",
    "        print(\"INCORRECT COUPON AT INDEX: {}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c922ea1",
   "metadata": {},
   "source": [
    "as no error was raised, the coupon values are all potentially legitimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f53ee970",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dirty_data)):\n",
    "    if float(dirty_data.loc[i,\"restaurant_rating\"])<0 or float(dirty_data.loc[i,\"restaurant_rating\"])>10:\n",
    "        print(\"INCORRECT RATING AT INDEX: {}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096ab5a",
   "metadata": {},
   "source": [
    "as no error was raised, the rating values are all potentially legitimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a14a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(dirty_data['travel_time_minutes']):\n",
    "    try:\n",
    "        fixed_data = int(dirty_data.loc[i,\"travel_time_minutes\"])\n",
    "    except ValueError:\n",
    "        print('INVALID TRAVEL TIME AT INDEX: {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91ccb5",
   "metadata": {},
   "source": [
    "as no error was raised, the travel time values are all potentially legitimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64af8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dirty_data)):\n",
    "    if float(dirty_data.loc[i,\"delivery_charges\"])<0:\n",
    "        print('INVALID CHARGES TIME AT INDEX: {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5dd60b",
   "metadata": {},
   "source": [
    "as no error was raised, the delivery charge values are all potentially legitimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9889f4",
   "metadata": {},
   "source": [
    "### 3.6 - validating order price\n",
    "this process is more complex than the other cleaning steps, as the item prices need to be determined before the order price can be checked for validity. the order price is also dependent on the coupon discount, so these columns need to be checked together. one the shopping baskeyt costs are detemined, if there is a discrepancy between the listed order price and the calculated one, the data needs to be changed. if is is possible to change the coupon value to produce the listed order price, this is done. otherwise the price is changed. \n",
    "#### 3.6.1 - determining item costs\n",
    "this is done using linear algebra. the order items, quantities, and total cost are extracted from the missing data (as this set contains no errors) and saved. independent vectors is then be isolated and used to construct a square matrix. guassian elimination is then performed to determine the costs of the items in the menu. to achieve this, the shopping carts are first extracted from the missing_data csv and are evaluated as a list of tuples. the restaurant id is also saved (as different restaurants have different menus). the  quantities of items in the cart are then saved to an ordered list (the order corresponds to the order of the items in the menu). it an item was not ordered, its given a quantity of 0. this is saved with the order cost to a dictionary as a tuple. this way, mulitple orders are stored as vectors to a dictionary for each restaurant. these orders are then appended to create a list of lists (which can be converted to a matrix. smypy is used to find linerarly independent order vectors (Mseifert 2017). these are used to create a new, square matrix, and np.linalg (Oliphant 2006) used to solve the system of equations. the solution correspond to item prices. this information is saved to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d0a9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vector sets of orders for each restaurant\n",
    "#initialising dictionaries\n",
    "order_dict = {}\n",
    "menu_dict = {}\n",
    "#looping through data\n",
    "for i in range(len(missing_data)):\n",
    "    #evaluating shopping cart\n",
    "    cart = ast.literal_eval(missing_data.loc[i, \"shopping_cart\"])\n",
    "    #if the restaurant already exists in the dictionary, further orders are appended to the value\n",
    "    #if the restaurant id doesnt yet exist in the dictionary, a new key is created\n",
    "    if missing_data.loc[i, \"restaurant_id\"] in order_dict.keys():\n",
    "        # the order is initialised as empty\n",
    "        order = []\n",
    "        #for each item on the menu, the quantity ordered is saved to the order list\n",
    "        for k in range(len(rest_data)):\n",
    "            if rest_data.loc[k, \"restaurant_id\"] == missing_data.loc[i, \"restaurant_id\"]:\n",
    "                for item in ast.literal_eval(rest_data.loc[k, \"menu_items\"]):\n",
    "                    item_found = False\n",
    "                    #if the item has been ordered, the quantity is saved\n",
    "                    for j in cart:\n",
    "                        if item == j[0]:\n",
    "                            order.append(j[1])\n",
    "                            item_found = True\n",
    "                    # if the item is not ordered, the quantity is saved as 0\n",
    "                    if not item_found:\n",
    "                        order.append(0)\n",
    "        #calculating non-discount price\n",
    "        price = float(missing_data.loc[i, \"order_price\"])/(1-(float(missing_data.loc[i, \"coupon_discount\"])/100))\n",
    "        #creating tuple\n",
    "        total = (order, price)\n",
    "        #saving order and cost to dictionary\n",
    "        order_dict[missing_data.loc[i, \"restaurant_id\"]].append(total)\n",
    "    \n",
    "    #if the restaurant id doesnt yet exist in the dictionary, a new key is created\n",
    "    else:\n",
    "        order_dict[missing_data.loc[i, \"restaurant_id\"]] = []\n",
    "        # the order is initialised as empty\n",
    "        order = []\n",
    "        #for each item on the menu, the quantity ordered is saved to the order list\n",
    "        for k in range(len(rest_data)):\n",
    "            if rest_data.loc[k, \"restaurant_id\"] == missing_data.loc[i, \"restaurant_id\"]:\n",
    "                rest_id = rest_data.loc[k, \"restaurant_id\"]\n",
    "                menu_dict[rest_id] = []\n",
    "                for item in ast.literal_eval(rest_data.loc[k, \"menu_items\"]):\n",
    "                    item_found = False\n",
    "                    menu_dict[rest_id].append(item)\n",
    "                    #if the item has been ordered, the quantity is saved\n",
    "                    for j in cart:\n",
    "                        if item == j[0]:\n",
    "                            order.append(j[1])\n",
    "                            item_found = True\n",
    "                    # if the item is not ordered, the quantity is saved as 0\n",
    "                    if not item_found:\n",
    "                        order.append(0)\n",
    "        #calculating non-discount price\n",
    "        price = float(missing_data.loc[i, \"order_price\"])/(1-(float(missing_data.loc[i, \"coupon_discount\"])/100))\n",
    "        #creating tuple\n",
    "        total = (order, price)\n",
    "        #saving order and cost to dictionary\n",
    "        order_dict[missing_data.loc[i, \"restaurant_id\"]].append(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d964fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'REST1137': [([0, 0, 0, 1, 0, 3, 2, 1, 0, 0], 110.98), ([2, 0, 0, 0, 0, 2, 0, 0, 0, 2], 89.64), ([0, 2, 1, 0, 0, 0, 3, 0, 0, 0], 67.3), ([1, 0, 0, 0, 0, 0, 0, 0, 1, 0], 21.97), ([1, 0, 0, 0, 0, 0, 1, 0, 0, 0], 23.16), ([1, 1, 0, 0, 0, 0, 1, 0, 2, 0], 45.81), ([0, 0, 0, 0, 0, 0, 0, 0, 2, 1], 16.14909090909091), ([0, 3, 0, 0, 0, 0, 0, 1, 0, 0], 45.55), ([1, 0, 1, 0, 0, 1, 0, 0, 1, 0], 68.54), ([2, 0, 0, 3, 0, 0, 0, 2, 0, 2], 122.94), ([0, 2, 0, 0, 0, 3, 0, 0, 0, 0], 92.2), ([0, 2, 0, 0, 0, 0, 0, 0, 0, 1], 29.29), ([0, 0, 0, 0, 2, 0, 2, 0, 0, 3], 41.91), ([0, 0, 0, 0, 0, 0, 1, 0, 3, 1], 28.06), ([1, 0, 1, 0, 0, 0, 2, 0, 0, 0], 53.5), ([0, 3, 2, 0, 0, 0, 0, 0, 0, 0], 83.37), ([2, 3, 0, 0, 0, 2, 0, 0, 3, 0], 130.6509090909091), ([0, 0, 1, 0, 0, 2, 0, 0, 2, 2], 90.93), ([0, 1, 3, 0, 0, 0, 3, 1, 0, 0], 112.71), ([0, 2, 0, 0, 0, 0, 3, 0, 0, 0], 43.51), ([0, 0, 0, 0, 2, 0, 0, 0, 0, 3], 28.81), ([3, 0, 2, 2, 0, 0, 0, 0, 0, 3], 153.26), ([2, 0, 1, 0, 0, 0, 0, 0, 0, 0], 57.01), ([2, 0, 0, 0, 0, 1, 0, 0, 1, 2], 72.21999999999998), ([0, 0, 1, 0, 3, 0, 0, 0, 0, 0], 42.57), ([0, 0, 0, 0, 3, 0, 0, 1, 0, 2], 39.4), ([0, 0, 0, 0, 0, 1, 3, 0, 0, 3], 58.72), ([2, 0, 2, 0, 0, 2, 0, 1, 0, 0], 136.12), ([0, 0, 0, 2, 1, 0, 0, 3, 0, 1], 80.53), ([2, 3, 0, 2, 0, 0, 0, 0, 0, 0], 108.57), ([1, 0, 0, 1, 2, 0, 0, 2, 0, 0], 68.4290909090909), ([0, 3, 1, 0, 0, 0, 3, 0, 0, 0], 79.23), ([0, 0, 0, 1, 2, 0, 0, 0, 0, 0], 32.3), ([0, 0, 0, 0, 3, 3, 0, 2, 0, 0], 106.64), ([0, 0, 0, 3, 0, 2, 0, 0, 0, 1], 110.33), ([0, 0, 1, 0, 0, 0, 1, 0, 2, 2], 51.92), ([1, 0, 0, 0, 0, 3, 0, 0, 3, 0], 101.03), ([0, 2, 3, 0, 2, 0, 0, 0, 0, 3], 124.03999999999999), ([0, 0, 0, 0, 0, 0, 1, 2, 0, 0], 26.07), ([0, 0, 2, 0, 0, 0, 3, 0, 3, 0], 83.31), ([3, 0, 0, 0, 0, 0, 0, 3, 0, 0], 79.11), ([1, 0, 0, 1, 0, 0, 0, 2, 1, 0], 61.27), ([0, 1, 0, 1, 0, 0, 0, 0, 3, 0], 47.79090909090909), ([0, 3, 0, 0, 0, 0, 0, 0, 1, 0], 41.15), ([0, 0, 3, 1, 0, 0, 1, 0, 0, 0], 97.7), ([3, 0, 0, 0, 0, 0, 0, 0, 3, 0], 65.91), ([0, 0, 0, 3, 0, 3, 1, 0, 0, 0], 134.23), ([1, 0, 1, 0, 0, 0, 0, 0, 1, 0], 45.76), ([1, 1, 0, 0, 2, 3, 0, 0, 0, 0], 109.4), ([1, 0, 0, 3, 0, 0, 0, 0, 0, 0], 75.95), ([0, 2, 0, 0, 2, 0, 0, 0, 0, 1], 41.81), ([3, 0, 2, 3, 0, 0, 0, 0, 1, 0], 162.11), ([0, 0, 1, 0, 2, 0, 3, 0, 0, 0], 55.96), ([0, 0, 0, 2, 0, 0, 1, 0, 0, 0], 46.11), ([0, 0, 0, 0, 0, 0, 0, 2, 0, 3], 35.81), ([0, 0, 0, 3, 0, 0, 2, 0, 1, 0], 77.8), ([3, 0, 3, 0, 0, 0, 2, 0, 0, 0], 134.3), ([0, 0, 2, 3, 0, 0, 0, 2, 1, 0], 131.8), ([0, 1, 3, 0, 0, 2, 0, 2, 0, 0], 148.38), ([0, 0, 2, 0, 0, 0, 0, 3, 0, 0], 76.86), ([3, 0, 1, 0, 0, 0, 0, 2, 0, 0], 93.14), ([1, 0, 0, 0, 1, 0, 0, 0, 2, 0], 33.59), ([0, 0, 0, 1, 0, 0, 0, 0, 0, 3], 36.07), ([0, 0, 0, 0, 1, 0, 0, 0, 3, 3], 38.63), ([0, 0, 0, 0, 0, 0, 1, 0, 0, 3], 22.84), ([1, 0, 0, 0, 0, 0, 3, 0, 0, 1], 41.69), ([2, 0, 0, 3, 0, 0, 2, 2, 0, 0], 125.18), ([0, 0, 0, 0, 0, 0, 2, 0, 0, 1], 18.529999999999998), ([0, 3, 0, 0, 0, 0, 2, 1, 0, 1], 64.08), ([2, 0, 0, 0, 2, 0, 0, 0, 0, 0], 45.74), ([0, 0, 0, 2, 0, 0, 0, 0, 3, 0], 55.64), ([0, 0, 3, 0, 3, 0, 0, 1, 0, 0], 99.91), ([0, 0, 0, 0, 0, 0, 3, 2, 0, 1], 44.6), ([0, 0, 0, 0, 3, 2, 0, 0, 0, 0], 64.34), ([0, 3, 3, 0, 1, 0, 0, 0, 2, 0], 124.14), ([0, 0, 2, 0, 0, 2, 0, 0, 0, 3], 109.43), ([0, 0, 1, 0, 0, 0, 0, 0, 2, 0], 34.51), ([0, 1, 2, 0, 0, 3, 0, 3, 0, 0], 157.13), ([3, 1, 0, 0, 0, 0, 0, 0, 0, 0], 61.76), ([0, 0, 3, 0, 0, 0, 0, 3, 1, 0], 106.01), ([1, 0, 2, 0, 0, 0, 0, 0, 0, 0], 64.19), ([0, 0, 0, 3, 0, 0, 1, 0, 1, 0], 71.25090909090909), ([0, 3, 0, 0, 0, 0, 0, 1, 0, 1], 50.98), ([0, 0, 1, 1, 1, 0, 0, 0, 0, 0], 49.83), ([0, 0, 2, 3, 1, 0, 0, 0, 0, 0], 113.18), ([3, 0, 0, 2, 2, 0, 0, 0, 0, 2], 112.77000000000001), ([0, 0, 0, 0, 3, 0, 0, 1, 3, 0], 44.62), ([0, 0, 0, 0, 0, 0, 1, 0, 0, 1], 11.98), ([0, 1, 0, 0, 1, 2, 0, 3, 0, 0], 93.03), ([0, 1, 0, 3, 0, 2, 0, 0, 0, 0], 116.83), ([0, 0, 0, 2, 0, 2, 0, 0, 0, 1], 90.55), ([3, 0, 0, 0, 1, 0, 0, 0, 0, 3], 72.38), ([0, 1, 1, 1, 0, 0, 0, 0, 1, 0], 60.86), ([0, 2, 0, 0, 0, 0, 0, 0, 2, 2], 45.44), ([0, 0, 0, 2, 0, 0, 0, 0, 3, 3], 71.92999999999999), ([0, 0, 0, 0, 0, 1, 3, 0, 0, 0], 42.43), ([0, 0, 1, 0, 0, 0, 0, 0, 1, 0], 29.15), ([0, 2, 0, 0, 0, 0, 2, 0, 0, 0], 36.96), ([0, 0, 0, 2, 0, 0, 0, 0, 0, 2], 50.42), ([3, 0, 0, 0, 0, 2, 0, 0, 3, 0], 111.47000000000001), ([0, 0, 0, 2, 0, 0, 0, 1, 2, 3], 76.33), ([3, 1, 0, 3, 1, 0, 0, 0, 0, 0], 127.35999999999999), ([0, 0, 0, 0, 3, 0, 0, 0, 0, 1], 24.21), ([0, 1, 0, 0, 3, 3, 0, 0, 0, 2], 109.91), ([0, 0, 0, 0, 0, 2, 0, 0, 2, 0], 56.28), ([0, 0, 0, 0, 1, 3, 0, 0, 2, 0], 85.32), ([0, 0, 0, 2, 3, 1, 0, 0, 0, 0], 81.11999999999999), ([0, 2, 0, 0, 3, 3, 0, 0, 3, 0], 127.06), ([3, 3, 0, 0, 0, 0, 3, 0, 2, 0], 115.99), ([3, 3, 0, 0, 0, 0, 0, 0, 0, 0], 85.62), ([0, 1, 0, 0, 0, 0, 2, 0, 0, 0], 25.03), ([0, 1, 0, 2, 0, 0, 2, 0, 0, 2], 75.44999999999999), ([1, 2, 0, 0, 0, 0, 0, 0, 1, 0], 45.83)], 'REST1572': [([0, 0, 0, 0, 1, 0, 2, 0], 60.22), ([0, 0, 1, 0, 0, 3, 0, 0], 37.94), ([2, 0, 0, 3, 0, 0, 0, 3], 149.93), ([0, 0, 3, 2, 0, 0, 2, 0], 93.88), ([2, 0, 0, 0, 0, 3, 1, 0], 83.09), ([0, 0, 0, 0, 0, 2, 2, 0], 58.94), ([0, 0, 0, 2, 2, 2, 0, 0], 107.96), ([3, 0, 0, 2, 1, 0, 0, 3], 168.68), ([1, 0, 3, 0, 3, 0, 0, 0], 101.11), ([3, 1, 1, 0, 0, 2, 0, 0], 88.77), ([0, 1, 0, 3, 0, 0, 0, 0], 74.3), ([0, 2, 0, 1, 0, 0, 0, 0], 47.7), ([0, 0, 0, 3, 0, 0, 3, 0], 116.43), ([0, 0, 0, 2, 0, 0, 1, 0], 58.98909090909091), ([1, 2, 0, 2, 0, 0, 0, 3], 141.3), ([0, 0, 0, 0, 3, 0, 1, 2], 125.81), ([0, 0, 2, 1, 0, 0, 0, 0], 31.019999999999996), ([1, 1, 0, 2, 0, 2, 0, 0], 91.77), ([3, 0, 0, 0, 3, 3, 0, 0], 149.31), ([0, 0, 0, 0, 0, 3, 3, 0], 88.41), ([0, 0, 0, 1, 1, 0, 0, 0], 43.14), ([0, 2, 0, 0, 1, 0, 0, 0], 50.48), ([1, 0, 1, 0, 0, 0, 2, 1], 77.8), ([0, 3, 0, 0, 0, 2, 0, 2], 101.26), ([0, 0, 0, 2, 2, 1, 0, 0], 97.12), ([1, 3, 0, 0, 0, 0, 0, 1], 76.4), ([0, 2, 0, 0, 0, 3, 0, 0], 60.04), ([0, 0, 0, 2, 0, 0, 1, 1], 78.14), ([0, 2, 1, 2, 0, 0, 0, 0], 73.3), ([3, 0, 0, 1, 0, 0, 2, 0], 105.35), ([0, 0, 0, 1, 3, 0, 3, 1], 164.09999999999997), ([0, 0, 0, 1, 0, 1, 1, 1], 68.8), ([0, 0, 0, 1, 1, 0, 3, 0], 99.02999999999999), ([0, 0, 3, 0, 0, 0, 3, 3], 129.6), ([0, 3, 0, 0, 0, 0, 3, 0], 97.17), ([0, 3, 0, 0, 0, 0, 1, 0], 59.91), ([2, 1, 0, 0, 0, 0, 0, 0], 45.7), ([3, 0, 0, 2, 0, 0, 0, 0], 88.27), ([0, 0, 0, 1, 0, 2, 2, 0], 79.11999999999999), ([0, 0, 1, 2, 3, 0, 0, 2], 152.95999999999998), ([0, 3, 0, 0, 1, 0, 0, 1], 83.39), ([1, 2, 0, 0, 2, 0, 0, 0], 89.41), ([0, 0, 3, 0, 1, 0, 2, 0], 76.48), ([1, 0, 3, 3, 0, 0, 0, 0], 92.77), ([0, 1, 0, 2, 0, 0, 3, 3], 167.46), ([0, 1, 0, 0, 3, 0, 3, 0], 138.53), ([2, 0, 0, 3, 0, 0, 3, 2], 186.67), ([0, 3, 0, 3, 0, 1, 3, 0], 168.54999999999998), ([0, 0, 0, 0, 0, 0, 3, 3], 113.34), ([0, 0, 0, 1, 1, 3, 0, 0], 75.66), ([0, 3, 0, 0, 1, 0, 0, 0], 64.24), ([0, 0, 0, 0, 1, 3, 2, 0], 92.74), ([0, 2, 1, 1, 2, 0, 0, 0], 99.04), ([0, 0, 0, 3, 0, 3, 0, 0], 93.05999999999999), ([0, 1, 3, 0, 0, 0, 0, 0], 30.02), ([0, 0, 1, 0, 2, 2, 2, 0], 110.28), ([0, 3, 0, 0, 0, 0, 1, 0], 59.91), ([0, 3, 0, 0, 2, 0, 0, 3], 144.65), ([0, 0, 1, 0, 0, 0, 3, 0], 61.31), ([1, 0, 0, 2, 0, 2, 0, 3], 135.46), ([1, 0, 1, 0, 3, 0, 0, 1], 109.42), ([2, 0, 0, 2, 0, 0, 3, 3], 185.64), ([0, 0, 1, 0, 0, 3, 0, 3], 95.39), ([1, 0, 0, 3, 0, 0, 0, 0], 76.50999999999999), ([0, 3, 0, 0, 0, 2, 3, 1], 138.0), ([0, 0, 2, 2, 0, 0, 0, 3], 108.65), ([0, 0, 1, 0, 3, 0, 1, 2], 131.23), ([0, 0, 1, 2, 3, 0, 0, 1], 133.8109090909091), ([3, 3, 0, 0, 1, 2, 0, 0], 133.83), ([2, 3, 0, 0, 0, 0, 3, 3], 186.55999999999997), ([0, 0, 0, 0, 2, 1, 0, 0], 56.76), ([2, 0, 0, 0, 1, 0, 0, 2], 93.2), ([1, 2, 2, 0, 1, 0, 0, 0], 77.29), ([2, 0, 0, 0, 1, 0, 0, 0], 54.9), ([0, 0, 2, 0, 3, 0, 2, 0], 116.97999999999999), ([2, 0, 0, 3, 0, 0, 0, 1], 111.63), ([0, 2, 0, 3, 0, 0, 0, 0], 88.06), ([2, 0, 2, 2, 0, 0, 0, 0], 83.14), ([0, 1, 0, 0, 1, 0, 3, 0], 92.60999999999999), ([0, 3, 2, 0, 0, 3, 0, 2], 122.94), ([0, 1, 2, 0, 3, 0, 0, 0], 93.48), ([0, 0, 3, 0, 2, 1, 0, 0], 73.02), ([0, 0, 2, 1, 1, 0, 2, 0], 91.24), ([0, 0, 0, 0, 0, 3, 0, 1], 51.67), ([2, 0, 0, 0, 2, 3, 0, 0], 110.38), ([2, 0, 0, 0, 0, 0, 3, 0], 87.83), ([0, 2, 1, 1, 0, 0, 0, 0], 53.12), ([0, 0, 1, 1, 0, 3, 0, 0], 58.12), ([2, 0, 0, 0, 0, 1, 0, 0], 42.78), ([2, 0, 2, 1, 0, 0, 0, 0], 62.96), ([0, 0, 0, 3, 0, 1, 0, 0], 71.38), ([0, 1, 0, 2, 1, 0, 0, 0], 77.08), ([0, 3, 0, 2, 0, 0, 1, 0], 100.27), ([0, 2, 0, 3, 3, 0, 0, 0], 156.94), ([1, 0, 0, 0, 0, 0, 2, 0], 53.23), ([0, 0, 3, 0, 1, 2, 2, 0], 98.16), ([3, 0, 1, 0, 0, 0, 0, 0], 53.33), ([0, 1, 0, 0, 0, 3, 0, 1], 65.43), ([0, 0, 0, 3, 0, 0, 0, 2], 98.83999999999999), ([0, 0, 2, 0, 0, 1, 0, 0], 21.68), ([0, 0, 2, 0, 1, 0, 0, 0], 33.8), ([0, 0, 0, 0, 2, 0, 3, 0], 101.81)], 'REST1946': [([0, 0, 3, 0, 1, 1, 3], 146.83), ([0, 0, 2, 1, 2, 0, 0], 99.82999999999998), ([3, 0, 3, 0, 0, 0, 3], 148.2), ([0, 1, 1, 0, 0, 1, 3], 106.24), ([2, 0, 0, 0, 0, 1, 2], 87.5), ([3, 0, 3, 0, 0, 0, 2], 128.08999999999997), ([0, 0, 1, 2, 0, 0, 2], 98.92), ([0, 0, 3, 3, 2, 2, 0], 194.81), ([0, 0, 0, 2, 3, 0, 1], 136.69), ([2, 0, 0, 0, 2, 0, 0], 77.53999999999999), ([3, 1, 0, 2, 0, 0, 2], 140.96), ([1, 0, 3, 2, 3, 0, 0], 175.3090909090909), ([0, 0, 0, 1, 1, 3, 1], 120.72000000000001), ([0, 0, 0, 1, 3, 1, 1], 132.84), ([2, 2, 2, 0, 0, 0, 0], 84.67999999999999), ([0, 0, 0, 0, 0, 3, 1], 74.53), ([0, 0, 0, 0, 3, 1, 0], 90.74000000000001), ([0, 2, 3, 3, 0, 0, 0], 136.23), ([1, 2, 0, 3, 0, 0, 1], 126.75), ([0, 0, 0, 1, 0, 3, 0], 76.41), ([1, 0, 0, 1, 1, 0, 0], 60.76), ([3, 0, 2, 1, 0, 0, 0], 95.14), ([3, 0, 2, 0, 3, 0, 3], 206.08), ([1, 3, 2, 0, 3, 0, 0], 155.76), ([0, 2, 2, 0, 0, 1, 3], 134.01), ([1, 3, 2, 0, 0, 0, 0], 83.16), ([0, 3, 1, 0, 0, 0, 3], 114.2), ([1, 2, 0, 3, 2, 0, 0], 155.04), ([3, 0, 0, 0, 2, 0, 0], 92.11), ([0, 3, 0, 0, 2, 3, 3], 202.3), ([2, 0, 3, 0, 0, 1, 3], 151.77), ([2, 0, 0, 3, 0, 0, 2], 135.33), ([2, 0, 0, 1, 1, 0, 0], 75.33), ([2, 0, 0, 2, 0, 0, 0], 73.11999999999999), ([0, 1, 0, 0, 2, 0, 2], 101.67), ([1, 0, 0, 1, 0, 3, 0], 90.97999999999999), ([1, 3, 0, 3, 0, 0, 2], 159.91), ([0, 0, 1, 3, 0, 0, 2], 120.91000000000001), ([0, 0, 2, 1, 0, 0, 0], 51.43), ([2, 0, 2, 0, 1, 3, 0], 137.2), ([2, 2, 0, 0, 3, 3, 0], 182.26), ([0, 0, 3, 0, 0, 3, 0], 98.58), ([2, 3, 0, 0, 2, 0, 0], 116.69), ([0, 1, 2, 0, 0, 2, 0], 78.77), ([0, 3, 3, 0, 0, 0, 0], 83.3090909090909), ([1, 0, 0, 2, 0, 0, 1], 78.66), ([0, 2, 2, 3, 2, 0, 0], 169.9090909090909), ([0, 1, 3, 0, 0, 3, 1], 131.74), ([0, 1, 0, 0, 0, 2, 0], 49.33), ([0, 0, 0, 3, 3, 0, 3], 198.9), ([0, 0, 2, 0, 3, 3, 0], 156.45999999999998), ([0, 0, 0, 3, 0, 2, 0], 102.25), ([0, 1, 0, 1, 0, 0, 0], 35.04), ([0, 2, 0, 0, 0, 2, 1], 82.49), ([0, 0, 0, 0, 0, 1, 3], 78.47), ([0, 2, 0, 2, 2, 0, 1], 138.59), ([3, 3, 0, 0, 2, 2, 0], 167.54000000000002), ([3, 0, 0, 2, 0, 0, 1], 107.80000000000001), ([0, 0, 3, 0, 1, 1, 3], 146.83), ([1, 3, 3, 0, 2, 0, 0], 146.28), ([0, 0, 2, 0, 0, 2, 1], 85.83), ([0, 3, 2, 0, 1, 2, 0], 129.07), ([0, 0, 0, 1, 2, 0, 0], 70.39), ([2, 0, 1, 0, 0, 1, 3], 122.33), ([3, 0, 0, 3, 2, 0, 0], 158.07999999999998), ([2, 0, 3, 0, 3, 0, 1], 166.01), ([0, 1, 0, 1, 0, 0, 0], 35.040000000000006), ([3, 2, 0, 0, 0, 0, 1], 89.92), ([3, 0, 0, 1, 0, 0, 0], 65.7), ([0, 0, 2, 3, 0, 3, 0], 149.8290909090909), ([2, 0, 2, 1, 0, 3, 0], 134.99), ([3, 0, 0, 3, 3, 0, 2], 222.5), ([2, 0, 1, 3, 0, 0, 0], 109.83), ([0, 2, 0, 0, 2, 0, 0], 74.5), ([3, 0, 1, 2, 3, 0, 0], 175.01), ([2, 0, 3, 2, 2, 0, 0], 165.68), ([0, 0, 3, 0, 3, 0, 2], 156.98), ([0, 0, 0, 1, 1, 2, 2], 122.69), ([0, 0, 0, 1, 0, 3, 0], 76.41000000000001), ([0, 3, 0, 0, 2, 3, 0], 141.96999999999997), ([3, 0, 0, 1, 0, 3, 0], 120.12), ([0, 0, 2, 3, 3, 0, 0], 168.01), ([0, 1, 3, 0, 2, 2, 0], 141.89), ([2, 1, 1, 0, 0, 0, 3], 117.24), ([3, 0, 0, 1, 0, 1, 0], 83.84), ([0, 0, 0, 3, 1, 0, 2], 130.39), ([3, 2, 0, 0, 2, 0, 2], 158.43), ([0, 1, 0, 0, 3, 3, 0], 140.07000000000002)], 'REST2155': [([0, 0, 0, 2, 0, 0, 2], 33.8), ([0, 0, 0, 2, 0, 0, 2], 33.8), ([3, 0, 3, 1, 0, 3, 0], 115.53), ([0, 2, 1, 0, 0, 2, 1], 77.02), ([0, 1, 0, 0, 3, 0, 0], 53.22), ([3, 3, 0, 2, 0, 1, 0], 87.47), ([2, 0, 0, 3, 0, 3, 3], 80.62), ([0, 1, 0, 0, 0, 0, 2], 36.74), ([0, 0, 0, 0, 3, 3, 0], 53.1), ([3, 1, 0, 2, 0, 0, 0], 50.130909090909086), ([1, 1, 0, 0, 0, 0, 0], 23.03), ([1, 0, 0, 0, 2, 0, 0], 31.81), ([2, 0, 0, 0, 1, 0, 0], 26.419999999999998), ([0, 0, 1, 2, 0, 0, 0], 37.1), ([0, 0, 3, 2, 1, 0, 2], 118.26), ([2, 1, 1, 3, 0, 0, 0], 73.68), ([0, 3, 0, 0, 0, 1, 0], 53.36), ([0, 2, 0, 0, 3, 0, 3], 100.32), ([0, 1, 0, 0, 3, 0, 2], 73.94), ([1, 3, 0, 0, 0, 2, 0], 65.67), ([3, 3, 0, 1, 1, 0, 0], 88.03), ([0, 2, 1, 0, 1, 0, 0], 68.46), ([0, 1, 1, 0, 3, 0, 0], 77.24), ([1, 3, 0, 0, 0, 3, 1], 81.33), ([0, 2, 0, 3, 0, 1, 3], 88.03999999999999), ([0, 0, 3, 0, 3, 0, 0], 109.25999999999999), ([1, 0, 0, 3, 0, 2, 0], 37.23), ([0, 3, 1, 0, 2, 3, 0], 112.78), ([0, 1, 2, 0, 0, 2, 0], 74.66), ([1, 2, 3, 0, 0, 3, 0], 127.01), ([0, 0, 0, 0, 3, 0, 2], 57.92000000000001), ([2, 0, 3, 2, 0, 0, 0], 99.16), ([0, 0, 0, 0, 0, 2, 2], 31.32), ([0, 3, 2, 0, 1, 0, 0], 108.5), ([0, 2, 3, 3, 0, 0, 1], 134.08), ([0, 2, 0, 0, 1, 3, 0], 60.339999999999996), ([0, 1, 1, 0, 1, 0, 2], 73.16), ([0, 0, 2, 3, 3, 0, 1], 115.22), ([0, 0, 0, 2, 1, 3, 2], 62.1), ([1, 0, 3, 2, 0, 0, 0], 92.15), ([0, 3, 2, 0, 0, 1, 0], 101.4), ([0, 0, 3, 1, 0, 0, 3], 109.68), ([0, 0, 3, 0, 0, 0, 3], 103.14), ([2, 3, 0, 0, 2, 2, 0], 97.48), ([0, 0, 3, 3, 0, 0, 1], 102.04), ([1, 1, 0, 3, 1, 0, 0], 55.050000000000004), ([1, 0, 3, 1, 2, 0, 0], 110.41090909090909), ([0, 1, 0, 0, 3, 0, 3], 84.3), ([0, 2, 0, 2, 0, 0, 0], 45.12), ([0, 2, 0, 0, 2, 2, 0], 67.44), ([1, 0, 2, 0, 0, 1, 1], 70.71), ([1, 3, 0, 0, 2, 0, 1], 90.23), ([0, 2, 0, 2, 1, 0, 0], 57.52), ([3, 2, 1, 2, 0, 0, 0], 90.17), ([1, 1, 0, 0, 0, 0, 0], 23.03), ([0, 0, 0, 2, 3, 0, 3], 81.36), ([2, 2, 0, 1, 0, 0, 1], 62.96), ([2, 0, 3, 0, 2, 2, 0], 121.47999999999999), ([2, 3, 0, 0, 2, 0, 0], 86.88), ([0, 0, 1, 3, 0, 1, 0], 48.940000000000005), ([0, 0, 0, 0, 0, 3, 2], 36.62), ([2, 0, 0, 0, 0, 2, 2], 45.34), ([2, 2, 1, 0, 0, 0, 1], 80.44000000000001), ([0, 0, 3, 3, 3, 3, 0], 144.78), ([0, 1, 0, 0, 3, 2, 3], 94.9), ([2, 0, 0, 1, 2, 0, 0], 45.36), ([3, 0, 0, 0, 2, 2, 0], 56.43), ([1, 3, 3, 0, 0, 2, 0], 137.73), ([0, 1, 0, 2, 2, 0, 0], 53.9), ([0, 0, 3, 3, 0, 3, 0], 107.58), ([0, 0, 3, 2, 1, 3, 0], 113.44), ([0, 2, 2, 0, 3, 3, 0], 133.18), ([0, 3, 0, 0, 3, 2, 0], 95.85999999999999), ([0, 1, 1, 0, 3, 0, 0], 77.24), ([3, 0, 0, 0, 0, 2, 0], 31.629999999999995), ([0, 1, 1, 2, 2, 0, 0], 77.92), ([0, 1, 0, 0, 0, 0, 1], 26.38), ([0, 0, 3, 0, 1, 1, 0], 89.75999999999999), ([0, 0, 0, 1, 0, 0, 2], 27.26), ([1, 0, 0, 3, 2, 3, 0], 67.33000000000001), ([0, 3, 0, 2, 0, 0, 0], 61.14), ([0, 0, 0, 2, 0, 2, 3], 54.760000000000005), ([0, 3, 0, 2, 1, 2, 0], 84.14), ([2, 3, 0, 3, 2, 0, 0], 106.5), ([0, 3, 0, 2, 0, 0, 0], 61.14), ([0, 0, 0, 0, 3, 0, 3], 68.28), ([2, 0, 0, 1, 0, 3, 1], 46.82), ([1, 0, 0, 2, 0, 0, 0], 20.09), ([0, 0, 0, 2, 0, 2, 2], 44.4), ([0, 0, 0, 0, 3, 1, 2], 63.22), ([3, 0, 0, 0, 0, 1, 0], 26.33), ([0, 0, 0, 1, 3, 1, 3], 80.12), ([0, 2, 2, 0, 0, 0, 0], 80.08), ([3, 0, 0, 3, 0, 3, 0], 56.55), ([3, 0, 1, 0, 2, 3, 0], 85.75), ([2, 3, 0, 0, 3, 0, 0], 99.28), ([0, 1, 0, 1, 0, 1, 0], 27.86), ([0, 3, 1, 2, 3, 0, 0], 122.35999999999999), ([3, 1, 2, 2, 0, 0, 0], 98.17), ([0, 2, 0, 0, 0, 0, 3], 63.12), ([0, 0, 0, 0, 2, 1, 2], 50.82), ([3, 1, 0, 0, 2, 0, 0], 61.85), ([3, 0, 0, 3, 0, 0, 3], 71.73), ([1, 3, 0, 3, 3, 0, 0], 111.89), ([0, 0, 3, 0, 1, 1, 0], 89.76), ([0, 0, 3, 0, 1, 0, 1], 94.82), ([0, 0, 3, 2, 3, 1, 0], 127.64), ([3, 0, 1, 0, 3, 3, 0], 98.14999999999999), ([0, 0, 0, 1, 0, 0, 2], 27.259999999999998), ([1, 0, 1, 0, 0, 1, 2], 57.05), ([0, 2, 0, 0, 2, 0, 1], 67.2), ([0, 0, 0, 2, 2, 0, 0], 37.879999999999995), ([0, 0, 0, 1, 3, 3, 0], 59.64)], 'REST2185': [([1, 1, 0, 0, 3, 0, 1], 100.61999999999999), ([0, 3, 3, 1, 0, 0, 3], 138.78), ([0, 2, 1, 0, 0, 1, 0], 66.17), ([0, 3, 0, 0, 1, 0, 2], 113.68), ([1, 0, 0, 2, 2, 0, 0], 59.86), ([1, 0, 2, 0, 3, 2, 0], 98.48), ([0, 1, 0, 1, 0, 2, 0], 51.1), ([2, 2, 0, 0, 3, 0, 2], 157.2), ([1, 1, 0, 3, 1, 0, 0], 75.1), ([0, 1, 0, 0, 3, 0, 0], 68.32), ([0, 0, 0, 0, 3, 3, 0], 75.81), ([0, 0, 3, 0, 0, 0, 1], 34.14), ([0, 0, 0, 1, 2, 3, 0], 66.77090909090909), ([0, 0, 0, 1, 0, 0, 2], 31.799999999999997), ([0, 0, 2, 0, 3, 0, 0], 58.08), ([3, 0, 0, 0, 3, 0, 0], 101.7), ([3, 0, 3, 0, 0, 3, 3], 149.73090909090908), ([2, 0, 0, 2, 1, 0, 0], 64.4), ([0, 0, 0, 0, 3, 2, 0], 65.22), ([2, 0, 0, 0, 3, 0, 2], 108.64), ([0, 0, 0, 1, 0, 1, 0], 16.23), ([0, 2, 0, 0, 2, 3, 2], 135.85), ([0, 0, 0, 2, 0, 2, 0], 32.46), ([0, 0, 0, 2, 3, 1, 0], 65.91), ([1, 0, 0, 1, 0, 0, 0], 24.86), ([0, 2, 3, 0, 3, 3, 0], 145.43), ([1, 0, 0, 0, 0, 0, 2], 45.38), ([2, 2, 0, 0, 0, 0, 0], 87.0), ([0, 1, 1, 0, 0, 2, 0], 52.48), ([2, 0, 0, 2, 3, 0, 1], 106.84), ([0, 0, 0, 3, 2, 0, 1], 59.36), ([0, 2, 0, 2, 0, 1, 0], 70.43090909090908), ([0, 0, 0, 0, 2, 3, 0], 61.130909090909086), ([3, 0, 0, 0, 1, 3, 0], 104.11), ([0, 0, 3, 2, 0, 0, 1], 45.42), ([3, 0, 0, 0, 0, 0, 3], 96.9), ([0, 2, 0, 0, 0, 0, 3], 87.8), ([2, 0, 0, 0, 0, 0, 3], 77.67999999999999), ([1, 0, 0, 0, 2, 0, 0], 48.58), ([3, 0, 1, 1, 0, 2, 0], 91.5), ([2, 2, 0, 3, 0, 0, 3], 143.16), ([3, 2, 0, 0, 0, 2, 2], 153.56), ([0, 1, 0, 1, 0, 0, 2], 56.08), ([3, 0, 0, 2, 1, 0, 3], 122.86), ([0, 0, 2, 2, 0, 0, 0], 25.32), ([2, 0, 1, 3, 0, 1, 0], 72.97), ([0, 0, 0, 0, 0, 2, 2], 47.34), ([2, 0, 0, 0, 0, 2, 0], 59.62), ([2, 0, 1, 1, 0, 3, 0], 82.86999999999999), ([0, 0, 2, 3, 0, 3, 3], 101.97), ([3, 3, 0, 1, 2, 0, 0], 165.5), ([0, 0, 2, 0, 0, 0, 3], 53.28), ([0, 2, 0, 0, 1, 3, 0], 95.01090909090908), ([0, 0, 1, 0, 0, 0, 2], 33.18), ([0, 2, 1, 0, 0, 0, 3], 94.82), ([0, 0, 3, 0, 1, 1, 0], 46.330000000000005), ([0, 0, 1, 0, 0, 1, 1], 30.69), ([0, 1, 3, 0, 3, 2, 0], 110.55999999999999), ([0, 0, 0, 0, 3, 0, 1], 57.12), ([0, 0, 2, 0, 2, 1, 2], 80.15), ([2, 1, 2, 0, 0, 0, 0], 76.76), ([0, 0, 1, 2, 2, 0, 2], 73.82), ([0, 1, 2, 0, 0, 3, 0], 70.09), ([0, 2, 0, 3, 3, 0, 0], 109.52), ([2, 0, 0, 2, 2, 0, 0], 79.08), ([0, 0, 0, 0, 2, 3, 1], 74.21), ([1, 0, 0, 3, 0, 0, 0], 36.14), ([0, 3, 0, 2, 2, 0, 0], 113.48), ([0, 2, 0, 0, 3, 3, 1], 137.45000000000002), ([1, 3, 0, 2, 0, 0, 2], 129.5), ([3, 0, 0, 3, 0, 0, 0], 74.58), ([3, 0, 3, 0, 0, 3, 0], 110.49), ([0, 2, 3, 1, 2, 0, 0], 104.62), ([1, 0, 0, 1, 2, 0, 0], 54.22), ([2, 0, 2, 0, 0, 0, 0], 52.48), ([0, 0, 1, 0, 0, 1, 1], 30.689999999999998), ([1, 0, 0, 0, 1, 0, 0], 33.9), ([0, 0, 3, 1, 0, 2, 0], 47.879999999999995), ([2, 0, 0, 1, 0, 0, 2], 70.24), ([0, 0, 0, 2, 1, 1, 1], 49.63), ([1, 0, 0, 2, 2, 0, 0], 59.86), ([1, 0, 0, 1, 0, 2, 0], 46.04), ([0, 2, 3, 3, 0, 1, 0], 97.13), ([0, 0, 0, 1, 0, 0, 3], 44.88)]}\n"
     ]
    }
   ],
   "source": [
    "print(order_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840dfe8f",
   "metadata": {},
   "source": [
    "As can be seen, the orders vectors have been saved to a dictionary successfully. however there are far more orders than items on the menu. solving linear algebra requires the reduction of a square matrix. hence, linearly independent orders need to be isolated to construct this (as randomly choosing some of the orders might lead to some item prices going unsolved). this system of linear equations can then be solved, giving prices for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dfe716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising dictionary\n",
    "price_dict = {}\n",
    "#looping through all the restaurants and corresponding orders\n",
    "for k,v in order_dict.items():\n",
    "    #initialising lists\n",
    "    values = []\n",
    "    totals = []\n",
    "    #appending orders and totals to create list of lists\n",
    "    for order in v:\n",
    "        values.append(order[0])\n",
    "        totals.append(order[1])\n",
    "    #converting lists of lists to array (matrix)\n",
    "    val_arr = np.array(values)\n",
    "    tot_arr = np.array(totals)\n",
    "    #identifying linearly independent vactors which can be used to solve equations\n",
    "    _, inds = sympy.Matrix(val_arr).T.rref() # (Mseifert 2017)\n",
    "    #creating new arrays of linearly independent vactors for order and their totals\n",
    "    value_arr = []\n",
    "    total_arr = []\n",
    "    #looping through list of indexes\n",
    "    for ind in inds:\n",
    "        value_arr.append(val_arr[ind])\n",
    "        total_arr.append(tot_arr[ind])\n",
    "    #converting to array (matrix)\n",
    "    value_arr = np.array(value_arr)\n",
    "    total_arr = np.array(total_arr)\n",
    "    #solving simultaneous equations\n",
    "    price_list = np.linalg.solve(value_arr,total_arr) # (Oliphant 2006)\n",
    "    #saving solutions to new dictionary\n",
    "    for rest_id,item in menu_dict.items():\n",
    "        if rest_id == k:\n",
    "            prices = []\n",
    "            for i in range(len(item)):\n",
    "                tup = (item[i], round(price_list[i], 4))\n",
    "                prices.append(tup)\n",
    "            price_dict[rest_id] = prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe92f8c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'REST1137': [('chicken biryani', 16.6102), ('chicken kebab', 11.9305), ('cocktails', 23.7898), ('crispy corn', 19.7811), ('fish', 6.2609), ('gulab jamun', 22.7802), ('mocktails', 6.5498), ('momos', 9.7586), ('murgh ghee roast', 5.3598), ('pizza', 5.4295)], 'REST1572': [('bbq chicken', 15.97), ('caramel pudding', 13.76), ('cocktails', 5.42), ('mocktails', 20.18), ('pizza', 22.96), ('sea food', 10.84), ('veg starter', 18.63), ('wedges', 19.15)], 'REST1946': [('biryani', 14.57), ('butter naan', 13.05), ('chicken tenders', 14.72), ('mutton pepper fry', 21.99), ('paneer malai tikka', 24.2), ('roti', 18.14), ('yakhni pulao', 20.11)], 'REST2155': [('biryani', 7.01), ('butter kulcha', 16.02), ('cheese naan', 24.02), ('kulfi', 6.54), ('palak paneer', 12.4), ('sweet lassi', 5.3), ('thali', 10.36)], 'REST2185': [('biryani', 19.22), ('custard', 24.28), ('jeera rice', 7.02), ('protein chapati', 5.64), ('rajma', 14.68), ('shahi paneer', 10.59), ('sweet lassi', 13.08)]}\n"
     ]
    }
   ],
   "source": [
    "#printing prices for inspection\n",
    "print(price_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5959eca",
   "metadata": {},
   "source": [
    "as can be seen, the calculations have been succesfful, and all the menu items have a determined price. where the calculated price included a large number of decimals, the value was rounded to 4 decimal places. this is done to avoid error propagation in later calculations. more explicitly, the order price is goven to 3 decimal places, so rounding to 3 now could affect the calculated order price. it is possible to leve these values unrounded, but it makes the dictionary difficult to inspect, and is also theoretically incorrect. No restaurant would list a food item like \"crispy corn\" as costing $\\text{\\$19.7811111132}$. Hence it is silly to save the values like this. arguably it is also silly to save the prices to 4 decimal places, but as previously indicated this is to avoid error propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b14fe",
   "metadata": {},
   "source": [
    "#### 3.6.2 - checking validity of order costs\n",
    "the price of each shopping cart is determined using the calculated values of item costs. if the calculated rice and listed order price differ, the data needs to be corrected. if the discount can be changed to produce the listed order charge, this is done. otherwise the order charge must be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71821df4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRICE CHANGED AT ROW: 43\n",
      "DISCOUNT CHANGED AT ROW: 95, DISCOUNT: 20\n",
      "PRICE CHANGED AT ROW: 106\n",
      "PRICE CHANGED AT ROW: 144\n",
      "PRICE CHANGED AT ROW: 221\n",
      "PRICE CHANGED AT ROW: 259\n",
      "PRICE CHANGED AT ROW: 310\n",
      "PRICE CHANGED AT ROW: 322\n",
      "DISCOUNT CHANGED AT ROW: 356, DISCOUNT: 45\n",
      "PRICE CHANGED AT ROW: 376\n",
      "PRICE CHANGED AT ROW: 417\n",
      "PRICE CHANGED AT ROW: 461\n",
      "DISCOUNT CHANGED AT ROW: 498, DISCOUNT: 40\n"
     ]
    }
   ],
   "source": [
    "#looping through each order\n",
    "for i in range(len(dirty_data)):\n",
    "    #converting shopping_cart to list\n",
    "    order = ast.literal_eval(dirty_data.loc[i, \"shopping_cart\"])\n",
    "    #finding restaurant id\n",
    "    rest_id = dirty_data.loc[i, \"restaurant_id\"]\n",
    "    #calculating total based on calculated item costs\n",
    "    total = 0\n",
    "    #looping through order and menu\n",
    "    for item in order:\n",
    "        for v in price_dict[rest_id]:\n",
    "            #if the item has been ordered, it is found in the menu and the cost added to the total\n",
    "            if v[0] == item[0]:\n",
    "                total+=(float(item[1])*float(v[1]))\n",
    "    #if the calculated price is different to the listed price (ignoring rounding errors)\n",
    "    if abs(round(total*(1-(float(dirty_data.loc[i, \"coupon_discount\"])/100)), 2) - round(float(dirty_data.loc[i, \"order_price\"]),2))>0.05:\n",
    "        discount_change = False\n",
    "        #if there exists a coupon which can produce the listed price, it is added\n",
    "        for discount in coupons:\n",
    "            if (round(total*(1-(discount/100)), 2)-round(float(dirty_data.loc[i, \"order_price\"]),2))<0.2 and (round(total, 2)-round(float(dirty_data.loc[i, \"order_price\"]),2))>0:\n",
    "                if int(dirty_data.loc[i, \"coupon_discount\"]) != discount:\n",
    "                    dirty_data.loc[i, \"coupon_discount\"] = discount\n",
    "                    changed_i.append(i)\n",
    "                    print(\"DISCOUNT CHANGED AT ROW: {}, DISCOUNT: {}\".format(i, discount))\n",
    "                    discount_change = True\n",
    "                    break\n",
    "        #if nothing can be done to produce the listed order price, the price is changed to reflect the calculated price (including discount)\n",
    "        if not discount_change:\n",
    "            dirty_data.loc[i, \"order_price\"] = round(total*(1-(float(dirty_data.loc[i, \"coupon_discount\"])/100)),3)\n",
    "            changed_i.append(i)\n",
    "            print(\"PRICE CHANGED AT ROW: {}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a771e37c",
   "metadata": {},
   "source": [
    "as per the outputs, some of the dataframe values were altered. the process appears to have been successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67890f",
   "metadata": {},
   "source": [
    "### 3.7 - checking shortest distance\n",
    "The shortest distance between the restaurant and the customer is calculated using Dijkstra algorithm (Wikipedia 2021) based on the graph created in Part 1. For each row of the dirty data datframe the restuarant node is extracted, and the customer node determined (by matching the customer latitude and longitude with the list of nodes). the shortest path is determined using nx.single_source_dijkstra (Hagberg et al., 2008) with the distance used to weight the edges. if this calculated shortest path does not match that listed in the data, the entry is changed to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "255f2668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORTEST PATH ALTERED AT INDEX: 15, FROM: 4336, TO: 1544\n",
      "SHORTEST PATH ALTERED AT INDEX: 82, FROM: 4842, TO: 2065\n",
      "SHORTEST PATH ALTERED AT INDEX: 84, FROM: 5591, TO: 1859\n",
      "SHORTEST PATH ALTERED AT INDEX: 88, FROM: 1800, TO: 2639\n",
      "SHORTEST PATH ALTERED AT INDEX: 129, FROM: 4334, TO: 4709\n",
      "SHORTEST PATH ALTERED AT INDEX: 249, FROM: 5870, TO: 3887\n",
      "SHORTEST PATH ALTERED AT INDEX: 306, FROM: 3085, TO: 5522\n",
      "SHORTEST PATH ALTERED AT INDEX: 393, FROM: 1091, TO: 5424\n",
      "SHORTEST PATH ALTERED AT INDEX: 415, FROM: 1752, TO: 3977\n",
      "SHORTEST PATH ALTERED AT INDEX: 423, FROM: 2428, TO: 3830\n",
      "SHORTEST PATH ALTERED AT INDEX: 467, FROM: 3770, TO: 3538\n",
      "SHORTEST PATH ALTERED AT INDEX: 486, FROM: 3961, TO: 3216\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dirty_data)-1):\n",
    "    c_lat = dirty_data.loc[i, \"customer_lat\"]\n",
    "    c_lon = dirty_data.loc[i, \"customer_lon\"]\n",
    "    r_id = dirty_data.loc[i, \"restaurant_id\"]\n",
    "    #finding restaurant node\n",
    "    for j in range(len(rest_data)):\n",
    "        if r_id == rest_data.loc[j, \"restaurant_id\"]:\n",
    "            r_node = rest_data.loc[j, \"rest_nodes\"]\n",
    "            break\n",
    "    #finding customer node\n",
    "    for k in range(len(nodes)):\n",
    "        if round(c_lat, 7) == round(nodes.loc[k, \"lat\"], 7) and round(c_lon, 7) == round(nodes.loc[k, \"lon\"], 7):\n",
    "            c_node = nodes.loc[k, \"node\"]\n",
    "            break\n",
    "    #calculating shortest path length (by distance)\n",
    "    distance,path=nx.single_source_dijkstra(G, source=r_node, target=c_node, weight='dist') # (Hagberg et al., (2008))    \n",
    "    #checking if calculated distance matches the one in dirty_data csv\n",
    "    if round(distance) != round(dirty_data.loc[i, \"shortest_distance_to_customer\"]):\n",
    "        changed_i.append(i)\n",
    "        print(\"SHORTEST PATH ALTERED AT INDEX: {}, FROM: {}, TO: {}\".format(i, dirty_data.loc[i, \"shortest_distance_to_customer\"], round(distance)))\n",
    "        dirty_data.loc[i, \"shortest_distance_to_customer\"] = round(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e156af",
   "metadata": {},
   "source": [
    "this cleaning has been successful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4020bb9",
   "metadata": {},
   "source": [
    "### 3.8 - checking travel time\n",
    "now the shortest distance have been verified as correct, the travel time and carrier vehicle can also be validated. the speed of each vehicle is given in the assessment outline. this average speed is used along with the shortest path distance to caluclate the travel time, using time=distance/velocity. if the listed travel time and calculated travel time dont match up an entry needs to be changed. if the carrier vehicle can be changed to produce the listed travel time, this is done, otherwise the travel time is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35d83b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VEHICLE CHANGED TO MATCH TIME AT ROW: 11, VEHICLE: Car, DIST: 3192, TIME: 6 CALC_TIME: 8\n",
      "VEHICLE CHANGED TO MATCH TIME AT ROW: 20, VEHICLE: Car, DIST: 1365, TIME: 3 CALC_TIME: 7\n",
      "TIME CHANGED TO MATCH VEHICLE AND DISTANCE AT ROW: 30 CALC_TIME: 5, TIME: 2\n",
      "VEHICLE CHANGED TO MATCH TIME AT ROW: 74, VEHICLE: Car, DIST: 3131, TIME: 8 CALC_TIME: 16\n",
      "VEHICLE CHANGED TO MATCH TIME AT ROW: 115, VEHICLE: Car, DIST: 2302, TIME: 5 CALC_TIME: 12\n",
      "TIME CHANGED TO MATCH VEHICLE AND DISTANCE AT ROW: 169 CALC_TIME: 11, TIME: 6\n",
      "TIME CHANGED TO MATCH VEHICLE AND DISTANCE AT ROW: 342 CALC_TIME: 5, TIME: 4\n",
      "TIME CHANGED TO MATCH VEHICLE AND DISTANCE AT ROW: 390 CALC_TIME: 10, TIME: 8\n",
      "TIME CHANGED TO MATCH VEHICLE AND DISTANCE AT ROW: 414 CALC_TIME: 21, TIME: 20\n"
     ]
    }
   ],
   "source": [
    "#saving speeds (in m/min) to dictionary\n",
    "speed_dict = {\"Bike\": 200, \"Motorbike\":500, \"Car\":25000/60}\n",
    "#looping through data\n",
    "for i in range(len(dirty_data)):\n",
    "    #rows only contain 1 error, so if the row has already been altered, it is not checked for another error\n",
    "    vehicle = dirty_data.loc[i, \"carrier_vehicle\"].title()\n",
    "    speed = speed_dict[vehicle]\n",
    "    #calculating rounded travel time using the given vehicle and distance\n",
    "    calc_tt = round(dirty_data.loc[i, \"shortest_distance_to_customer\"]/speed)\n",
    "    listed_t = round(dirty_data.loc[i, \"travel_time_minutes\"])\n",
    "    # if the listed and caluclated values do not match, something needs to be fixed\n",
    "    if calc_tt-listed_t>=1:\n",
    "        v_changed = False\n",
    "        #looping through speeds\n",
    "        possible_v = []\n",
    "        for k,v in speed_dict.items():\n",
    "            #if the vehicle can be changed to produce the given travel time, this is done\n",
    "            if round(dirty_data.loc[i, \"shortest_distance_to_customer\"]/v) == listed_t:\n",
    "                possible_v.append((listed_t - (dirty_data.loc[i, \"shortest_distance_to_customer\"]/v), k))\n",
    "                v_changed = True\n",
    "        if v_changed:\n",
    "            if len(possible_v)==1:\n",
    "                dirty_data.loc[i, \"carrier_vehicle\"] = possible_v[0][1]\n",
    "                print(\"VEHICLE CHANGED TO MATCH TIME AT ROW: {}, VEHICLE: {}, DIST: {}, TIME: {} CALC_TIME: {}\".format(i, k, dirty_data.loc[i, \"shortest_distance_to_customer\"], dirty_data.loc[i, \"travel_time_minutes\"], calc_tt))\n",
    "                changed_i.append(i)\n",
    "            elif abs(possible_v[0][0])<abs(possible_v[1][0]):\n",
    "                dirty_data.loc[i, \"carrier_vehicle\"] = possible_v[0][1]\n",
    "                print(\"VEHICLE CHANGED TO MATCH TIME AT ROW: {}, VEHICLE: {}, DIST: {}, TIME: {} CALC_TIME: {}\".format(i, k, dirty_data.loc[i, \"shortest_distance_to_customer\"], dirty_data.loc[i, \"travel_time_minutes\"], calc_tt))\n",
    "                changed_i.append(i)\n",
    "            else:\n",
    "                dirty_data.loc[i, \"carrier_vehicle\"] = possible_v[1][1]\n",
    "                print(\"VEHICLE CHANGED TO MATCH TIME AT ROW: {}, VEHICLE: {}, DIST: {}, TIME: {} CALC_TIME: {}\".format(i, k, dirty_data.loc[i, \"shortest_distance_to_customer\"], dirty_data.loc[i, \"travel_time_minutes\"], calc_tt))\n",
    "                changed_i.append(i)\n",
    "        #if the vehicle wasn't changed, the travel time is changed\n",
    "        else:\n",
    "            time = int(round(dirty_data.loc[i, \"shortest_distance_to_customer\"]/speed_dict[vehicle], 0))\n",
    "            dirty_data.loc[i, \"travel_time_minutes\"] = time\n",
    "            changed_i.append(i)\n",
    "            print(\"TIME CHANGED TO MATCH VEHICLE AND DISTANCE AT ROW: {} CALC_TIME: {}, TIME: {}\".format(i, calc_tt, listed_t))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d676748",
   "metadata": {},
   "source": [
    "as per the outputs, the cleaning appears to have been successful, although it should be noted that often the rounded travel time for motorbikes and cars results in the same value. for this reason, previously altered data is excluded from the processing. as the assessment outline indicates there is only one error per row. this is prevent an already altered row from being arbitaraily changed again. it is also worth checking that where a courier appears more than once, they've used the same vehicle both times. this can be done after the vehicle syntax is fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fca8f6",
   "metadata": {},
   "source": [
    "### 3.9 - fixing vehicle syntax\n",
    "\"bike\" and \"Bike\" consitute different entries in the dataframe. Hence the formatting needs to be standardised to whatever is most common (if valid). To determine the common entry format value_counts() is used. the string values can then be converted to the common capitalisation. This method also allows for any spelling mistakes to be identified. this is done after the vehicles have been changed so that fixing capitalisation and then changing vehicle is not counted as 2 changes (as it is only one error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "190c89f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Motorbike    183\n",
       "Car          157\n",
       "Bike         155\n",
       "bike           3\n",
       "car            1\n",
       "motorbike      1\n",
       "Name: carrier_vehicle, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data[\"carrier_vehicle\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b665b",
   "metadata": {},
   "source": [
    "this indicates that the title capitalisation is the standard format. so anomalies are altered to match this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e7b3216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARRIER VEHICLE CHANGED AT INDEX: 63 FROM: bike\n",
      "CARRIER VEHICLE CHANGED AT INDEX: 176 FROM: car\n",
      "CARRIER VEHICLE CHANGED AT INDEX: 367 FROM: bike\n",
      "CARRIER VEHICLE CHANGED AT INDEX: 397 FROM: bike\n",
      "CARRIER VEHICLE CHANGED AT INDEX: 450 FROM: motorbike\n"
     ]
    }
   ],
   "source": [
    "#looping through the data\n",
    "for i in range(len(dirty_data)):\n",
    "    #editing a dataframe is slow, this way the data is only edited if it is not correctly cased\n",
    "    if dirty_data.loc[i,\"carrier_vehicle\"]!=dirty_data.loc[i,\"carrier_vehicle\"].title():\n",
    "        changed_i.append(i)\n",
    "        print(\"CARRIER VEHICLE CHANGED AT INDEX: {} FROM: {}\".format(i, dirty_data.loc[i,\"carrier_vehicle\"]))\n",
    "        dirty_data.loc[i,\"carrier_vehicle\"] = dirty_data.loc[i,\"carrier_vehicle\"].title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bb6a0",
   "metadata": {},
   "source": [
    "### 3.10 - checking restaurant ratings\n",
    "using the ratings produced in Part 1 (via semantic analysis), the listed ratings can be corrected. as these errors can occur along with other errors in the row, the changed indexes are not added to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f48884c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTAURANT RATING CHANGED AT ROW: 2 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 3 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 4 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 6 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 7 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 8 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 9 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 12 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 14 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 15 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 19 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 22 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 25 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 27 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 28 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 29 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 32 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 33 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 35 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 36 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 38 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 39 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 40 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 41 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 42 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 43 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 45 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 49 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 50 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 51 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 53 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 55 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 57 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 58 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 59 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 60 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 63 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 65 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 66 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 67 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 77 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 79 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 80 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 82 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 85 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 86 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 87 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 88 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 89 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 90 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 91 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 92 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 100 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 103 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 107 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 110 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 114 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 118 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 120 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 126 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 128 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 131 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 132 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 134 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 135 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 136 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 137 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 142 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 143 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 144 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 147 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 148 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 149 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 152 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 153 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 154 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 157 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 158 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 159 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 162 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 163 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 167 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 168 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 169 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 171 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 172 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 174 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 175 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 176 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 180 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 181 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 189 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 191 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 197 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 198 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 202 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 203 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 205 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 206 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 210 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 211 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 212 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 213 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 215 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 218 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 219 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 221 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 223 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 227 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 233 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 234 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 237 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 238 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 239 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 240 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 241 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 242 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 243 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 244 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 245 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 246 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 249 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 253 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 254 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 255 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 256 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 257 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 258 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 260 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 265 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 267 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 268 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 269 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 271 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 272 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 273 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 274 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 276 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 277 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 278 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 281 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 284 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 286 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 288 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 290 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 291 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 292 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 297 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 298 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 300 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 301 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 304 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 309 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 311 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 313 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 314 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 315 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 316 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 318 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 324 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 327 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 328 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 333 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 334 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 336 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 337 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 339 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 342 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 343 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 347 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 350 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 353 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 359 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 360 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 364 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 372 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 374 FROM: 7.68 TO: 9.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTAURANT RATING CHANGED AT ROW: 375 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 377 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 378 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 379 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 381 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 384 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 385 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 386 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 387 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 388 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 389 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 392 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 394 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 395 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 401 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 406 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 407 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 408 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 410 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 411 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 413 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 414 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 416 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 418 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 419 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 420 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 421 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 422 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 423 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 424 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 427 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 428 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 437 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 438 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 441 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 444 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 445 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 446 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 448 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 450 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 451 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 453 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 455 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 457 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 458 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 462 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 463 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 467 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 469 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 470 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 471 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 472 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 482 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 485 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 486 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 487 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 490 FROM: 7.42 TO: 9.28\n",
      "RESTAURANT RATING CHANGED AT ROW: 491 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 492 FROM: 7.68 TO: 9.6\n",
      "RESTAURANT RATING CHANGED AT ROW: 493 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 494 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 495 FROM: 7.63 TO: 9.54\n",
      "RESTAURANT RATING CHANGED AT ROW: 496 FROM: 3.97 TO: 4.96\n",
      "RESTAURANT RATING CHANGED AT ROW: 497 FROM: 6.54 TO: 8.18\n",
      "RESTAURANT RATING CHANGED AT ROW: 499 FROM: 6.54 TO: 8.18\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dirty_data)):\n",
    "    rest_id = dirty_data.loc[i, \"restaurant_id\"]\n",
    "    if float(dirty_data.loc[i, \"restaurant_rating\"]) != float(rest_rating[rest_id]):\n",
    "        print(\"RESTAURANT RATING CHANGED AT ROW: {} FROM: {} TO: {}\".format(i, dirty_data.loc[i, \"restaurant_rating\"], rest_rating[rest_id]))\n",
    "        dirty_data.loc[i, \"restaurant_rating\"] = rest_rating[rest_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d1f1b",
   "metadata": {},
   "source": [
    "as suspected, the restaurant ratings contain many errors. inspecting the output, the fixing appears to be successful and consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a530a",
   "metadata": {},
   "source": [
    "### Part 3.11 - Validating Outputs\n",
    "as per the assessment outline, there is only one error per row (excluding rating). over the course of the cleaning, any time a row was altered, its index was saved to a list. if an index appears more than once, this indicates an error with the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c30121aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MATCHES FOUND\n"
     ]
    }
   ],
   "source": [
    "#seeing how many times rows have been altered\n",
    "counts = Counter(changed_i)\n",
    "#the counts dictionary is searched to find any keys which correspond to two changed in the indexed row\n",
    "try:\n",
    "    list(counts.keys())[list(counts.values()).index(2)]\n",
    "except:\n",
    "    print(\"NO MATCHES FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49382b23",
   "metadata": {},
   "source": [
    "as this code returns no matches, it indicates that no rows of the dataframe have been changed twice (inspection of the dictionary also validates this). Hence, the cleaning has been successful. However, due to bugs in the round function for numpy, not all the data is correctly formatted. more specifically, where round() (to a whole number) was applied to a float 64 value, the returned number ends with \".0\". this is inconsistent with the other data in the dataframe and needs to be fixed. this can be done by converting the number to a string and using regex to remove the \".0\". the dataframes are then inspected to check for any other issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca5a5fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-90022de19d2b>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dirty_data[\"shortest_distance_to_customer\"] = dirty_data[\"shortest_distance_to_customer\"].str.replace(r'.0', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>carrier_vehicle</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>delivery_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD056142</td>\n",
       "      <td>REST2155</td>\n",
       "      <td>CUST01589</td>\n",
       "      <td>COUR4804</td>\n",
       "      <td>-37.822437</td>\n",
       "      <td>144.992793</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>03:29:40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('biryani', 3), ('palak paneer', 3), ('kulfi'...</td>\n",
       "      <td>10</td>\n",
       "      <td>79.911</td>\n",
       "      <td>2123</td>\n",
       "      <td>4</td>\n",
       "      <td>9.54</td>\n",
       "      <td>3.8424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD252312</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST08448</td>\n",
       "      <td>COUR1944</td>\n",
       "      <td>-37.803101</td>\n",
       "      <td>144.963384</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>22:40:52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('rajma', 1), ('biryani', 3), ('shahi paneer'...</td>\n",
       "      <td>0</td>\n",
       "      <td>109.750</td>\n",
       "      <td>2967</td>\n",
       "      <td>6</td>\n",
       "      <td>8.18</td>\n",
       "      <td>3.6061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD341034</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST05976</td>\n",
       "      <td>COUR3565</td>\n",
       "      <td>-37.821442</td>\n",
       "      <td>144.966559</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>09:21:45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('protein chapati', 1), ('shahi paneer', 1), ...</td>\n",
       "      <td>45</td>\n",
       "      <td>43.720</td>\n",
       "      <td>1112</td>\n",
       "      <td>2</td>\n",
       "      <td>8.18</td>\n",
       "      <td>4.0609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD077971</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST01709</td>\n",
       "      <td>COUR4317</td>\n",
       "      <td>-37.824604</td>\n",
       "      <td>145.000542</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>01:58:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('chicken kebab', 1), ('pizza', 3), ('momos',...</td>\n",
       "      <td>0</td>\n",
       "      <td>80.280</td>\n",
       "      <td>3686</td>\n",
       "      <td>9</td>\n",
       "      <td>9.60</td>\n",
       "      <td>3.5915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD177038</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST07938</td>\n",
       "      <td>COUR2243</td>\n",
       "      <td>-37.813178</td>\n",
       "      <td>144.973869</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>07:11:12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('paneer malai tikka', 2), ('yakhni pulao', 2)]</td>\n",
       "      <td>0</td>\n",
       "      <td>88.620</td>\n",
       "      <td>3865</td>\n",
       "      <td>9</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.5343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD056142      REST2155   CUST01589   COUR4804    -37.822437    144.992793   \n",
       "1  ORD252312      REST2185   CUST08448   COUR1944    -37.803101    144.963384   \n",
       "2  ORD341034      REST2185   CUST05976   COUR3565    -37.821442    144.966559   \n",
       "3  ORD077971      REST1137   CUST01709   COUR4317    -37.824604    145.000542   \n",
       "4  ORD177038      REST1946   CUST07938   COUR2243    -37.813178    144.973869   \n",
       "\n",
       "        date      time  is_peak_time  is_weekend carrier_vehicle  \\\n",
       "0 2020-05-02  03:29:40             0           1       Motorbike   \n",
       "1 2020-03-27  22:40:52             0           0       Motorbike   \n",
       "2 2020-12-06  09:21:45             0           1       Motorbike   \n",
       "3 2020-03-16  01:58:40             0           0             Car   \n",
       "4 2020-06-29  07:11:12             0           0             Car   \n",
       "\n",
       "                                       shopping_cart  coupon_discount  \\\n",
       "0  [('biryani', 3), ('palak paneer', 3), ('kulfi'...               10   \n",
       "1  [('rajma', 1), ('biryani', 3), ('shahi paneer'...                0   \n",
       "2  [('protein chapati', 1), ('shahi paneer', 1), ...               45   \n",
       "3  [('chicken kebab', 1), ('pizza', 3), ('momos',...                0   \n",
       "4   [('paneer malai tikka', 2), ('yakhni pulao', 2)]                0   \n",
       "\n",
       "   order_price shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0       79.911                          2123                    4   \n",
       "1      109.750                          2967                    6   \n",
       "2       43.720                          1112                    2   \n",
       "3       80.280                          3686                    9   \n",
       "4       88.620                          3865                    9   \n",
       "\n",
       "   restaurant_rating  delivery_charges  \n",
       "0               9.54            3.8424  \n",
       "1               8.18            3.6061  \n",
       "2               8.18            4.0609  \n",
       "3               9.60            3.5915  \n",
       "4               4.96            4.5343  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data[\"shortest_distance_to_customer\"] = dirty_data['shortest_distance_to_customer'].apply(str)\n",
    "dirty_data[\"shortest_distance_to_customer\"] = dirty_data[\"shortest_distance_to_customer\"].str.replace(r'.0', '')\n",
    "dirty_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87210178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-509a5d8b5427>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  missing_data[\"shortest_distance_to_customer\"] = missing_data[\"shortest_distance_to_customer\"].str.replace(r'.0', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>carrier_vehicle</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>delivery_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD221584</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST06498</td>\n",
       "      <td>COUR4108</td>\n",
       "      <td>-37.825367</td>\n",
       "      <td>144.982814</td>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>06:31:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('crispy corn', 1), ('momos', 1), ('mocktails...</td>\n",
       "      <td>20</td>\n",
       "      <td>88.784</td>\n",
       "      <td>2742</td>\n",
       "      <td>5</td>\n",
       "      <td>9.60</td>\n",
       "      <td>3.4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD185757</td>\n",
       "      <td>REST1572</td>\n",
       "      <td>CUST08996</td>\n",
       "      <td>COUR2623</td>\n",
       "      <td>-37.812679</td>\n",
       "      <td>144.959576</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>15:53:24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('pizza', 1), ('veg starter', 2)]</td>\n",
       "      <td>45</td>\n",
       "      <td>33.121</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>9.28</td>\n",
       "      <td>3.6992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD058245</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST09230</td>\n",
       "      <td>COUR2476</td>\n",
       "      <td>-37.799510</td>\n",
       "      <td>144.935378</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>22:48:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('chicken tenders', 3), ('yakhni pulao', 3), ...</td>\n",
       "      <td>0</td>\n",
       "      <td>146.830</td>\n",
       "      <td>3312</td>\n",
       "      <td>17</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.6442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD182651</td>\n",
       "      <td>REST1572</td>\n",
       "      <td>CUST03209</td>\n",
       "      <td>COUR0581</td>\n",
       "      <td>-37.811442</td>\n",
       "      <td>144.927331</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>08:06:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('cocktails', 1), ('sea food', 3)]</td>\n",
       "      <td>0</td>\n",
       "      <td>37.940</td>\n",
       "      <td>4292</td>\n",
       "      <td>21</td>\n",
       "      <td>9.28</td>\n",
       "      <td>4.1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD189538</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST08767</td>\n",
       "      <td>COUR3877</td>\n",
       "      <td>-37.815733</td>\n",
       "      <td>144.982268</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>11:40:13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('gulab jamun', 2), ('pizza', 2), ('chicken b...</td>\n",
       "      <td>20</td>\n",
       "      <td>71.712</td>\n",
       "      <td>1576</td>\n",
       "      <td>4</td>\n",
       "      <td>9.60</td>\n",
       "      <td>2.7549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD221584      REST1137   CUST06498   COUR4108    -37.825367    144.982814   \n",
       "1  ORD185757      REST1572   CUST08996   COUR2623    -37.812679    144.959576   \n",
       "2  ORD058245      REST1946   CUST09230   COUR2476    -37.799510    144.935378   \n",
       "3  ORD182651      REST1572   CUST03209   COUR0581    -37.811442    144.927331   \n",
       "4  ORD189538      REST1137   CUST08767   COUR3877    -37.815733    144.982268   \n",
       "\n",
       "         date      time  is_peak_time  is_weekend carrier_vehicle  \\\n",
       "0  2020-11-26  06:31:38             0           0       Motorbike   \n",
       "1  2020-09-27  15:53:24             0           1             Car   \n",
       "2  2020-11-24  22:48:47             0           0            Bike   \n",
       "3  2020-05-29  08:06:35             0           0            Bike   \n",
       "4  2020-12-28  11:40:13             0           0             Car   \n",
       "\n",
       "                                       shopping_cart  coupon_discount  \\\n",
       "0  [('crispy corn', 1), ('momos', 1), ('mocktails...               20   \n",
       "1                 [('pizza', 1), ('veg starter', 2)]               45   \n",
       "2  [('chicken tenders', 3), ('yakhni pulao', 3), ...                0   \n",
       "3                [('cocktails', 1), ('sea food', 3)]                0   \n",
       "4  [('gulab jamun', 2), ('pizza', 2), ('chicken b...               20   \n",
       "\n",
       "   order_price shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0       88.784                          2742                    5   \n",
       "1       33.121                            45                    3   \n",
       "2      146.830                          3312                   17   \n",
       "3       37.940                          4292                   21   \n",
       "4       71.712                          1576                    4   \n",
       "\n",
       "   restaurant_rating  delivery_charges  \n",
       "0               9.60            3.4576  \n",
       "1               9.28            3.6992  \n",
       "2               4.96            4.6442  \n",
       "3               9.28            4.1049  \n",
       "4               9.60            2.7549  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data[\"shortest_distance_to_customer\"] = missing_data['shortest_distance_to_customer'].apply(str)\n",
    "missing_data[\"shortest_distance_to_customer\"] = missing_data[\"shortest_distance_to_customer\"].str.replace(r'.0', '')\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91a8d106",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>carrier_id</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>is_peak_time</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>carrier_vehicle</th>\n",
       "      <th>shopping_cart</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>order_price</th>\n",
       "      <th>shortest_distance_to_customer</th>\n",
       "      <th>travel_time_minutes</th>\n",
       "      <th>delivery_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD080681</td>\n",
       "      <td>REST1946</td>\n",
       "      <td>CUST13978</td>\n",
       "      <td>COUR2927</td>\n",
       "      <td>-37.813016</td>\n",
       "      <td>144.951538</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>08:38:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Car</td>\n",
       "      <td>[('roti', 3), ('paneer malai tikka', 1), ('but...</td>\n",
       "      <td>10</td>\n",
       "      <td>120.744</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD046142</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST11790</td>\n",
       "      <td>COUR4300</td>\n",
       "      <td>-37.804585</td>\n",
       "      <td>144.967553</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>12:11:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('shahi paneer', 3), ('rajma', 2), ('biryani'...</td>\n",
       "      <td>45</td>\n",
       "      <td>74.640</td>\n",
       "      <td>3019</td>\n",
       "      <td>6</td>\n",
       "      <td>5.8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD005100</td>\n",
       "      <td>REST2155</td>\n",
       "      <td>CUST06044</td>\n",
       "      <td>COUR1049</td>\n",
       "      <td>-37.806317</td>\n",
       "      <td>144.941575</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>17:16:29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>[('butter kulcha', 1), ('thali', 3)]</td>\n",
       "      <td>20</td>\n",
       "      <td>37.680</td>\n",
       "      <td>5828</td>\n",
       "      <td>12</td>\n",
       "      <td>3.9266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD030320</td>\n",
       "      <td>REST1137</td>\n",
       "      <td>CUST07409</td>\n",
       "      <td>COUR1647</td>\n",
       "      <td>-37.823595</td>\n",
       "      <td>144.967131</td>\n",
       "      <td>2020-11-28</td>\n",
       "      <td>01:50:46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('momos', 3), ('chicken kebab', 2), ('crispy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>92.700</td>\n",
       "      <td>2344</td>\n",
       "      <td>12</td>\n",
       "      <td>4.7621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD312831</td>\n",
       "      <td>REST2185</td>\n",
       "      <td>CUST00686</td>\n",
       "      <td>COUR1688</td>\n",
       "      <td>-37.817256</td>\n",
       "      <td>144.962170</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>04:17:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bike</td>\n",
       "      <td>[('custard', 1), ('jeera rice', 3), ('protein ...</td>\n",
       "      <td>0</td>\n",
       "      <td>62.260</td>\n",
       "      <td>1085</td>\n",
       "      <td>5</td>\n",
       "      <td>3.4256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id restaurant_id customer_id carrier_id  customer_lat  customer_lon  \\\n",
       "0  ORD080681      REST1946   CUST13978   COUR2927    -37.813016    144.951538   \n",
       "1  ORD046142      REST2185   CUST11790   COUR4300    -37.804585    144.967553   \n",
       "2  ORD005100      REST2155   CUST06044   COUR1049    -37.806317    144.941575   \n",
       "3  ORD030320      REST1137   CUST07409   COUR1647    -37.823595    144.967131   \n",
       "4  ORD312831      REST2185   CUST00686   COUR1688    -37.817256    144.962170   \n",
       "\n",
       "         date      time  is_peak_time  is_weekend carrier_vehicle  \\\n",
       "0  2020-08-04  08:38:14             0           0             Car   \n",
       "1  2020-02-16  12:11:52             1           1       Motorbike   \n",
       "2  2020-07-16  17:16:29             0           0       Motorbike   \n",
       "3  2020-11-28  01:50:46             0           1            Bike   \n",
       "4  2020-06-08  04:17:08             0           0            Bike   \n",
       "\n",
       "                                       shopping_cart  coupon_discount  \\\n",
       "0  [('roti', 3), ('paneer malai tikka', 1), ('but...               10   \n",
       "1  [('shahi paneer', 3), ('rajma', 2), ('biryani'...               45   \n",
       "2               [('butter kulcha', 1), ('thali', 3)]               20   \n",
       "3  [('momos', 3), ('chicken kebab', 2), ('crispy ...                0   \n",
       "4  [('custard', 1), ('jeera rice', 3), ('protein ...                0   \n",
       "\n",
       "   order_price  shortest_distance_to_customer  travel_time_minutes  \\\n",
       "0      120.744                           1792                    4   \n",
       "1       74.640                           3019                    6   \n",
       "2       37.680                           5828                   12   \n",
       "3       92.700                           2344                   12   \n",
       "4       62.260                           1085                    5   \n",
       "\n",
       "   delivery_charges  \n",
       "0            3.8732  \n",
       "1            5.8251  \n",
       "2            3.9266  \n",
       "3            4.7621  \n",
       "4            3.4256  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20326dcd",
   "metadata": {},
   "source": [
    "on inspection, all other values in the dataframes appear to be in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "708c58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_counts = Counter(dirty_data['carrier_id'])\n",
    "#the counts dictionary is searched to find any keys which correspond to two changed in the indexed row\n",
    "carrier_list = [k for k,v in car_counts.items() if int(v) >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6222f684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COUR4804': ['Motorbike', 'Motorbike'],\n",
       " 'COUR2381': ['Car', 'Car'],\n",
       " 'COUR2635': ['Motorbike', 'Motorbike'],\n",
       " 'COUR0179': ['Motorbike', 'Motorbike'],\n",
       " 'COUR1911': ['Bike', 'Bike'],\n",
       " 'COUR4858': ['Motorbike', 'Motorbike'],\n",
       " 'COUR4154': ['Bike', 'Bike'],\n",
       " 'COUR1811': ['Car', 'Car'],\n",
       " 'COUR4770': ['Car', 'Car'],\n",
       " 'COUR2387': ['Motorbike', 'Motorbike', 'Motorbike'],\n",
       " 'COUR2339': ['Car', 'Car'],\n",
       " 'COUR0795': ['Motorbike', 'Motorbike'],\n",
       " 'COUR0554': ['Bike', 'Car'],\n",
       " 'COUR2709': ['Motorbike', 'Motorbike', 'Motorbike'],\n",
       " 'COUR0738': ['Motorbike', 'Motorbike'],\n",
       " 'COUR3478': ['Car', 'Car'],\n",
       " 'COUR4526': ['Motorbike', 'Motorbike'],\n",
       " 'COUR0462': ['Motorbike', 'Motorbike'],\n",
       " 'COUR1831': ['Bike', 'Bike'],\n",
       " 'COUR3109': ['Car', 'Car'],\n",
       " 'COUR4624': ['Bike', 'Motorbike', 'Bike'],\n",
       " 'COUR3007': ['Motorbike', 'Motorbike'],\n",
       " 'COUR2152': ['Car', 'Car'],\n",
       " 'COUR4969': ['Bike', 'Bike'],\n",
       " 'COUR3141': ['Motorbike', 'Motorbike']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_dict= {}\n",
    "dup_car = dirty_data[dirty_data['carrier_id'].isin(carrier_list)]\n",
    "dup_car = dup_car.reset_index(drop=True)\n",
    "for i in range(len(dup_car)):\n",
    "    if dup_car.loc[i, 'carrier_id'] in car_dict.keys():\n",
    "        car_dict[dup_car.loc[i, 'carrier_id']].append(dup_car.loc[i, 'carrier_vehicle'])\n",
    "    else:\n",
    "        car_dict[dup_car.loc[i, 'carrier_id']] = [dup_car.loc[i, 'carrier_vehicle']]\n",
    "car_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d988aa0",
   "metadata": {},
   "source": [
    "as can be seen, all the carriers are consistent in their vehicle use, so it appears no errors have been introduced during the data cleaning. the formats of the other dataframes also seem consistent so the data is ready to be exported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf304c",
   "metadata": {},
   "source": [
    "## Part 4 -  Exporting Data\n",
    "now the data has been processed, it can be exported to csv's for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "095c918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data.to_csv('32565895_dirty_solution.csv')\n",
    "missing_data.to_csv('32565895_missing_solution.csv')\n",
    "outlier_data.to_csv('32565895_outlier_solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d1b9c",
   "metadata": {},
   "source": [
    "# References\n",
    "Aric A. Hagberg, Daniel A. Schult and Pieter J. Swart (2008), “Exploring network structure, dynamics, and function using NetworkX”, in Proceedings of the 7th Python in Science Conference (SciPy2008), Gäel Varoquaux, Travis Vaught, and Jarrod Millman (Eds), (Pasadena, CA USA), pp. 11–15\n",
    "<br>\n",
    "<br>\n",
    "Pedregosa, F., Varoquaux, G.,  Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,  Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E. (2011), “Scikit-learn: Machine Learning in Python”, Journal of Machine Learning Research 12, pp. 2825-2830\n",
    "<br>\n",
    "<br>\n",
    "Bird, S., Loper, E., Klein, E., (2009), \"Natural Language Processing with Python\", O’Reilly Media Inc.\n",
    "<br>\n",
    "<br>\n",
    "NIST/SEMATECH (2013), \"e-Handbook of Statistical Methods - 7.1.6 What are outliers in the data?\", Retrieved 01/10/2021, from https://doi.org/10.18434/M32189\n",
    "<br>\n",
    "<br>\n",
    "Mseifert. (2017), \"How to find linearly independent rows from a matrix\", Retrieved 01/10/2021, from https://stackoverflow.com/questions/28816627/how-to-find-linearly-independent-rows-from-a-matrix\n",
    "<br>\n",
    "<br>\n",
    "Oliphant, T. (2006) \"A guide to NumPy\", USA: Trelgol Publishing\n",
    "<br>\n",
    "<br>\n",
    "Wikipedia (2021), \"Dijkstra's algorithm\", Retrieved 01/10/2021, from https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311d4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
